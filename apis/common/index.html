<!--
Licensed to the Apache Software Foundation (ASF) under one
or more contributor license agreements.  See the NOTICE file
distributed with this work for additional information
regarding copyright ownership.  The ASF licenses this file
to you under the Apache License, Version 2.0 (the
"License"); you may not use this file except in compliance
with the License.  You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing,
software distributed under the License is distributed on an
"AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
KIND, either express or implied.  See the License for the
specific language governing permissions and limitations
under the License.
-->
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
    <title>Apache Flink 1.1.0 中文文档: 基本概念</title>
    <link rel="shortcut icon" href="/1.1.0/page/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/1.1.0/page/favicon.ico" type="image/x-icon">

    <!-- Bootstrap -->
    <link href="//cdn.bootcss.com/bootstrap/3.3.4/css/bootstrap.min.css" rel="stylesheet">
    <link rel="stylesheet" href="/1.1.0/page/css/flink.css">
    <link rel="stylesheet" href="/1.1.0/page/css/syntax.css">
    <link rel="stylesheet" href="/1.1.0/page/css/codetabs.css">
    
    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
  </head>
  <body>
    
    
    <div style="position:fixed; bottom:0; left:0; z-index:99999; width:100%; text-align:center; padding:15px; border-top:1px dashed #CE4B65; background:#f6f0e3; font-weight:bold">
       本文档适用于 Apache Flink 的旧版本，建议使用 <a href="http://doc.flink-china.org/latest/">最新版本的文档</a> 。
    </div>
    
    

    
    





    <!-- Top navbar. -->
    <nav class="navbar navbar-default navbar-fixed-top">
      <div class="container">
        <!-- The logo. -->
        <div class="navbar-header">
          <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </button>
          <div class="navbar-logo">
            <a href="http://flink-china.org"><img alt="Apache Flink" src="/1.1.0/page/img/navbar-brand-logo.jpg"></a>
          </div>
        </div><!-- /.navbar-header -->

        <!-- The navigation links. -->
        <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
          <ul class="nav navbar-nav">
            <li class="hidden-sm "><a href="/1.1.0/">中文文档 1.1</a></li>

            <li class="hidden-sm "><a href="/1.1.0/features.html">特性</a></li>

            <!-- Quickstart -->
            <li class="dropdown">
              <a href="/1.1.0/quickstart" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">快速起步<span class="caret"></span></a>
              <ul class="dropdown-menu" role="menu">
                
                
                <li class=""><a href="/1.1.0/quickstart/setup_quickstart.html">安装</a></li>
                
                <li class=""><a href="/1.1.0/quickstart/run_example_quickstart.html">例子: 维基百科编辑流</a></li>
                
                <li class=""><a href="/1.1.0/quickstart/java_api_quickstart.html">Java API</a></li>
                
                <li class=""><a href="/1.1.0/quickstart/scala_api_quickstart.html">Scala API</a></li>
                
              </ul>
            </li>

            <!-- Setup -->
            <li class="dropdown">
              <a href="/1.1.0/setup" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">安装 <span class="caret"></span></a>
              <ul class="dropdown-menu" role="menu">
                
                
                <li class=""><a href="/1.1.0/setup/building.html">构建 Flink</a></li>
                
                <li class=""><a href="/1.1.0/setup/config.html">Configuration</a></li>
                

                <li class="divider"></li>
                <li role="presentation" class="dropdown-header"><strong>部署</strong></li>
                
                
                <li class=""><a href="/1.1.0/setup/local_setup.html">本地</a></li>
                
                <li class=""><a href="/1.1.0/setup/cluster_setup.html">集群 (Standalone)</a></li>
                
                <li class=""><a href="/1.1.0/setup/yarn_setup.html">YARN</a></li>
                
                <li class=""><a href="/1.1.0/setup/gce_setup.html">Google Compute Engine</a></li>
                
                <li class=""><a href="/1.1.0/setup/jobmanager_high_availability.html">High Availability</a></li>
                
              </ul>
            </li>

            <!-- Programming Guides -->
            <li class="dropdown active">
              <a href="/1.1.0/apis" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">编程指南 <span class="caret"></span></a>
              <ul class="dropdown-menu" role="menu">
                
                
                <li class="active"><a href="/1.1.0/apis/common/"><strong>基本概念</strong></a></li>
                
                <li class=""><a href="/1.1.0/apis/streaming/"><strong>Streaming 指南</strong> (DataStream API)</a></li>
                
                <li class=""><a href="/1.1.0/apis/batch/"><strong>Batch 指南</strong> (DataSet API)</a></li>
                
                <li class=""><a href="/1.1.0/apis/best_practices.html">Best Practices</a></li>
                
                <li class=""><a href="/1.1.0/apis/cli.html">命令行接口（CLI）</a></li>
                
                <li class=""><a href="/1.1.0/apis/local_execution.html">本地执行</a></li>
                
                <li class=""><a href="/1.1.0/apis/cluster_execution.html">Cluster Execution</a></li>
                
                <li class=""><a href="/1.1.0/apis/scala_shell.html">Scala Shell</a></li>
                
                <li class=""><a href="/1.1.0/apis/java8.html">Java 8</a></li>
                
                <li class=""><a href="/1.1.0/apis/metrics.html">Metrics</a></li>
                
              </ul>
            </li>

            <!-- Libraries -->
            <li class="dropdown">
              <a href="/1.1.0/libs" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">类库 <span class="caret"></span></a>
                <ul class="dropdown-menu" role="menu">
                  
                  
                  <li class=""><a href="/1.1.0/apis/batch/libs/gelly.html">Graphs: Gelly</a></li>
                  
                  <li class=""><a href="/1.1.0/apis/streaming/libs/cep.html">CEP</a></li>
                  
                  <li class=""><a href="/1.1.0/apis/batch/libs/ml/">Machine Learning</a></li>
                  
                  <li class=""><a href="/1.1.0/apis/batch/libs/table.html">Relational: Table</a></li>
                  
              </ul>
            </li>

            <!-- Internals -->
            <li class="dropdown">
              <a href="/1.1.0/internals" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">内部 <span class="caret"></span></a>
              <ul class="dropdown-menu" role="menu">
                <li role="presentation" class="dropdown-header"><strong>Contribute</strong></li>
                <li><a href="http://flink.apache.org/how-to-contribute.html"><small><span class="glyphicon glyphicon-new-window"></span></small> How to Contribute</a></li>
                <li><a href="http://flink.apache.org/contribute-code.html#coding-guidelines"><small><span class="glyphicon glyphicon-new-window"></span></small> Coding Guidelines</a></li>
                
                
                <li class=""><a href="/1.1.0/internals/ide_setup.html">IDE Setup</a></li>
                
                <li class=""><a href="/1.1.0/internals/logging.html">Logging</a></li>
                
                <li class=""><a href="/1.1.0/internals/general_arch.html">Architecture and Process Model</a></li>
                
                <li class=""><a href="/1.1.0/internals/stream_checkpointing.html">Data Streaming的容错机制</a></li>
                
                <li class=""><a href="/1.1.0/internals/types_serialization.html">Type Extraction and Serialization</a></li>
                
                <li class=""><a href="/1.1.0/internals/monitoring_rest_api.html">Monitoring REST API</a></li>
                
                <li class=""><a href="/1.1.0/internals/job_scheduling.html">Jobs and Scheduling</a></li>
                
                <li class=""><a href="/1.1.0/internals/add_operator.html">How-To: Add an Operator</a></li>
                
              </ul>
            </li>

          </ul>
          <ul class="nav navbar-nav navbar-right">
            <li><a class="hidden-sm" href="http://blog.flink-china.org" target="_blank">
            <small><span class="glyphicon glyphicon-new-window"></span></small> 博客</a></li>
            <li class="hidden-sm "><a href="/1.1.0/about/">关于本站</a></li>
          </ul>
          <form class="navbar-form navbar-right hidden-sm hidden-md" role="search" action="/1.1.0/search-results.html">
            <div class="form-group">
              <input type="text" class="form-control" size="16px" name="q" placeholder="Search all pages">
            </div>
            <button type="submit" class="btn btn-default">搜索</button>
          </form>
        </div><!-- /.navbar-collapse -->
      </div><!-- /.container -->
    </nav>


    

    <!-- Main content. -->
    <div class="container">
      
      
<div class="row">

  
  
  <div class="col-md-8 col-md-offset-2 text">
    <!-- Artifact name change warning. Remove for the 1.0 release. -->
    
    <div class="panel panel-default">
      <div class="panel-body"><strong>重要</strong>: 依赖于Scala的maven artifacts现在会添加一个Scala主版本的后缀，例如 "2.10" 或 "2.11". 请查阅<a href="https://cwiki.apache.org/confluence/display/FLINK/Maven+artifact+names+suffixed+with+Scala+version">迁移指南</a>.</div>
    </div>
    

    <h1>基本概念</h1>


<p>Flink 程序是在分布式集合上实现转换（比如 filtering, mapping, updating state, joining, grouping, defining windows, aggregating）的普通程序。 数据集合根据一些 source（比如 文件，kafka 或本地的集合）初始化创建。 通过 sinks 返回的结果，sink 可以写入到（分布式）文件或标准输出（如终端命令行）。Flink 运行在各种环境下，standalone 或嵌入到其他程序中。 可能在本地 JVM 中执行，或多台机器的集群上运行。</p>

<p>根据数据源的类型，例如有界或无界的数据源，用户可以实现一个批处理(batch program)或一个流式程序(streaming program), 其中 DataSet API 用于前者，DataStream API 用于后者。本文档介绍这两种 API 共通的一些基本概念。更详细的编程指南请参考 <a href="/1.1.0/apis/streaming/index.html">Streaming 指南</a> 和
<a href="/1.1.0/apis/batch/index.html">Batch 指南</a>。</p>

<p><strong>注意</strong>: 在本文档介绍 API 使用的实例中，我们将使用 <code>StreamingExecutionEnvironment</code> 和 DataStream API, 这些概念同样适用于 DataSet API，仅仅是换成 <code>ExecutionEnvironment</code> and DataSet 而已。</p>

<ul id="markdown-toc">
  <li><a href="#关联-flink" id="markdown-toc-关联-flink">关联 Flink</a></li>
  <li><a href="#dataset-和-datastream" id="markdown-toc-dataset-和-datastream">DataSet 和 DataStream</a></li>
  <li><a href="#剖析-flink-程序" id="markdown-toc-剖析-flink-程序">剖析 Flink 程序</a></li>
  <li><a href="#延迟计算lazy-evaluation" id="markdown-toc-延迟计算lazy-evaluation">延迟计算（Lazy Evaluation）</a></li>
  <li><a href="#指定-keys" id="markdown-toc-指定-keys">指定 Keys</a></li>
  <li><a href="#定义转换函数" id="markdown-toc-定义转换函数">定义转换函数</a></li>
  <li><a href="#支持的数据类型" id="markdown-toc-支持的数据类型">支持的数据类型</a></li>
  <li><a href="#执行配置" id="markdown-toc-执行配置">执行配置</a></li>
  <li><a href="#程序打包和分布式执行" id="markdown-toc-程序打包和分布式执行">程序打包和分布式执行</a></li>
  <li><a href="#累加器和计数器" id="markdown-toc-累加器和计数器">累加器和计数器</a></li>
  <li><a href="#并发执行" id="markdown-toc-并发执行">并发执行</a>    <ul>
      <li><a href="#operator-级别" id="markdown-toc-operator-级别">Operator 级别</a></li>
      <li><a href="#执行环境级别" id="markdown-toc-执行环境级别">执行环境级别</a></li>
      <li><a href="#客户端级别" id="markdown-toc-客户端级别">客户端级别</a></li>
      <li><a href="#系统级别" id="markdown-toc-系统级别">系统级别</a></li>
    </ul>
  </li>
  <li><a href="#执行计划" id="markdown-toc-执行计划">执行计划</a></li>
</ul>

<p><a id="linking-with-flink"></a></p>

<h2 id="关联-flink">关联 Flink</h2>

<p>要用 Flink 编写程序，你需要引入与你使用的编程语言相对应的 Flink library。</p>

<p>最简单的引入 Flink 到项目的方式是使用快速起步中的脚本，比如 <a href="/1.1.0/quickstart/java_api_quickstart.html">Java API</a> 或是 <a href="/1.1.0/quickstart/scala_api_quickstart.html">Scala API</a>。也可以通过下面的 maven 插件来创建一个空的项目，<code>archetypeVersion</code> 可以选择其他稳定版本或预发版本（<code>-SNAPSHOT</code>）版本。</p>

<div class="codetabs">
  <div data-lang="java">

    <figure class="highlight"><pre><code class="language-bash" data-lang="bash">mvn archetype:generate <span class="se">\</span>
    -DarchetypeGroupId<span class="o">=</span>org.apache.flink <span class="se">\</span>
    -DarchetypeArtifactId<span class="o">=</span>flink-quickstart-java <span class="se">\</span>
    -DarchetypeVersion<span class="o">=</span>1.1.0</code></pre></figure>

  </div>
  <div data-lang="scala">

    <figure class="highlight"><pre><code class="language-bash" data-lang="bash">mvn archetype:generate <span class="se">\</span>
    -DarchetypeGroupId<span class="o">=</span>org.apache.flink <span class="se">\</span>
    -DarchetypeArtifactId<span class="o">=</span>flink-quickstart-scala <span class="se">\</span>
    -DarchetypeVersion<span class="o">=</span>1.1.0</code></pre></figure>

  </div>
</div>

<p>如果想要把 Flink 加入到现有的 maven 项目中，则需要添加依赖，将下面这段添加到项目 <em>pom.xml</em> 的 <em>dependencies</em> 块中：</p>

<div class="codetabs">
  <div data-lang="java">

    <figure class="highlight"><pre><code class="language-xml" data-lang="xml"><span class="c">&lt;!-- Use this dependency if you are using the DataStream API --&gt;</span>
<span class="nt">&lt;dependency&gt;</span>
  <span class="nt">&lt;groupId&gt;</span>org.apache.flink<span class="nt">&lt;/groupId&gt;</span>
  <span class="nt">&lt;artifactId&gt;</span>flink-streaming-java_2.10<span class="nt">&lt;/artifactId&gt;</span>
  <span class="nt">&lt;version&gt;</span>1.1.0<span class="nt">&lt;/version&gt;</span>
<span class="nt">&lt;/dependency&gt;</span>
<span class="c">&lt;!-- Use this dependency if you are using the DataSet API --&gt;</span>
<span class="nt">&lt;dependency&gt;</span>
  <span class="nt">&lt;groupId&gt;</span>org.apache.flink<span class="nt">&lt;/groupId&gt;</span>
  <span class="nt">&lt;artifactId&gt;</span>flink-java<span class="nt">&lt;/artifactId&gt;</span>
  <span class="nt">&lt;version&gt;</span>1.1.0<span class="nt">&lt;/version&gt;</span>
<span class="nt">&lt;/dependency&gt;</span>
<span class="nt">&lt;dependency&gt;</span>
  <span class="nt">&lt;groupId&gt;</span>org.apache.flink<span class="nt">&lt;/groupId&gt;</span>
  <span class="nt">&lt;artifactId&gt;</span>flink-clients_2.10<span class="nt">&lt;/artifactId&gt;</span>
  <span class="nt">&lt;version&gt;</span>1.1.0<span class="nt">&lt;/version&gt;</span>
<span class="nt">&lt;/dependency&gt;</span></code></pre></figure>

  </div>
  <div data-lang="scala">

    <figure class="highlight"><pre><code class="language-xml" data-lang="xml"><span class="c">&lt;!-- Use this dependency if you are using the DataStream API --&gt;</span>
<span class="nt">&lt;dependency&gt;</span>
  <span class="nt">&lt;groupId&gt;</span>org.apache.flink<span class="nt">&lt;/groupId&gt;</span>
  <span class="nt">&lt;artifactId&gt;</span>flink-streaming-scala_2.10<span class="nt">&lt;/artifactId&gt;</span>
  <span class="nt">&lt;version&gt;</span>1.1.0<span class="nt">&lt;/version&gt;</span>
<span class="nt">&lt;/dependency&gt;</span>
<span class="c">&lt;!-- Use this dependency if you are using the DataSet API --&gt;</span>
<span class="nt">&lt;dependency&gt;</span>
  <span class="nt">&lt;groupId&gt;</span>org.apache.flink<span class="nt">&lt;/groupId&gt;</span>
  <span class="nt">&lt;artifactId&gt;</span>flink-scala_2.10<span class="nt">&lt;/artifactId&gt;</span>
  <span class="nt">&lt;version&gt;</span>1.1.0<span class="nt">&lt;/version&gt;</span>
<span class="nt">&lt;/dependency&gt;</span>
<span class="nt">&lt;dependency&gt;</span>
  <span class="nt">&lt;groupId&gt;</span>org.apache.flink<span class="nt">&lt;/groupId&gt;</span>
  <span class="nt">&lt;artifactId&gt;</span>flink-clients_2.10<span class="nt">&lt;/artifactId&gt;</span>
  <span class="nt">&lt;version&gt;</span>1.1.0<span class="nt">&lt;/version&gt;</span>
<span class="nt">&lt;/dependency&gt;</span></code></pre></figure>

    <p><strong>重要:</strong> 如果使用 Scala API，则需要 import 下面两者其中一个。</p>

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">import</span> <span class="nn">org.apache.flink.api.scala._</span></code></pre></figure>

    <p>or</p>

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">import</span> <span class="nn">org.apache.flink.api.scala.createTypeInformation</span></code></pre></figure>

    <p>原因是 Flink 需要分析程序中使用的类型，从而生成 serializers 和 comparaters 。通过 import 上述两者之一，可以开启一个隐式的转换，为 Flink 的操作创建类型信息。</p>

  </div>
</div>

<h4 id="scala-依赖版本">Scala 依赖版本</h4>

<p>因为scala 2.10 binary 不兼容2.11，因此我们提供多个 artifacts 来支持这两种 Scala 版本。</p>

<p>从 0.10 开始，我们为 2.10 和 2.11 交叉编译了所有的 Flink 模块。如果你想要将你的程序跑在 Scala 2.11 的 Flink 上，只需要在对应模块的 <code>artifactId</code> 后加上 <code>_2.11</code> 版本后缀。</p>

<p>如果你想要用 Scala 2.11 自己编译 Flink，可以参考 <a href="/1.1.0/setup/building.html#scala-versions">编译 Flink</a>。</p>

<h4 id="hadoop-依赖版本">Hadoop 依赖版本</h4>

<p>如果 Flink 要运行在 Hadoop 上，请选择正确的 Hadoop 版本，详情请参考 <a href="http://flink.apache.org/downloads.html">下载页面</a> 可用版本列表，同时了解如何关联自定义版本的 Hadoop。</p>

<p>想要关联最新的 SNAPSHOT 版本的代码，请参考 <a href="http://flink.apache.org/how-to-contribute.html#snapshots-nightly-builds">这篇教程</a>。</p>

<p><em>flink-clients</em> 依赖仅仅是本地模式需要（如测试调试）。 如果想要 <a href="/1.1.0/apis/cluster_execution.html">在集群模式下运行</a> ，可以忽略这个依赖。</p>

<p><a href="#top" class="top pull-right"><span class="glyphicon glyphicon-chevron-up"></span> Back to top</a></p>

<h2 id="dataset-和-datastream">DataSet 和 DataStream</h2>

<p>Flink 用特别的类 DataSet 和 DataStream 来表示程序中的数据。用户可以认为它们是含有重复数据的不可修改的集合(collection)。当使用 DataSet 时，数据是有限的，而DataStream 中元素的数量是无限的。</p>

<p>在几个关键点上， 这些集合与 Java 集合是不同的。首先，它们是不可修改的，这意味着它们一旦被创建出来，就不能添加或删除元素。你也不能简单地查看内部的元素。</p>

<p>在一个 Flink 程序中，一个集合是通过添加一个 source 来初始化获得的，新的集合可以通过转换（transformation）得到，转换的 API 函数有 <code>map</code>，<code>filter</code> 等。</p>

<p><a id="anatomy-of-a-flink-program"></a></p>

<h2 id="剖析-flink-程序">剖析 Flink 程序</h2>

<p>Flink 程序看起来就像常规程序一样转换数据集合。每一个程序都由一些基本部分组成：</p>

<ol>
  <li>获得一个 <code>execution environment</code>，</li>
  <li>加载/创建初始数据，</li>
  <li>指定在该数据上进行的转换，</li>
  <li>指定计算结果的存储地方，</li>
  <li>启动程序执行。</li>
</ol>

<div class="codetabs">
  <div data-lang="java">

    <p>现在，我们将大致介绍下每一步，你可以参考相应的章节了解更多。注意所有的 Java DataSet API 核心类都可以在 <a href="https://github.com/apache/flink/blob/master//flink-java/src/main/java/org/apache/flink/api/java">org.apache.flink.api.java</a> 中找到，而所有的 Java DataStream API 核心类可以在 <a href="https://github.com/apache/flink/blob/master//flink-streaming-java/src/main/java/org/apache/flink/streaming/api">org.apache.flink.streaming.api</a> 中找到。</p>

    <p><code>StreamExecutionEnvironment</code> 是所有 Flink 程序的基础，你可以使用 <code>StreamExecutionEnvironment</code> 中的这些静态方法来获得：</p>

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="n">getExecutionEnvironment</span><span class="o">()</span>

<span class="n">createLocalEnvironment</span><span class="o">()</span>

<span class="n">createRemoteEnvironment</span><span class="o">(</span><span class="n">String</span> <span class="n">host</span><span class="o">,</span> <span class="kt">int</span> <span class="n">port</span><span class="o">,</span> <span class="n">String</span><span class="o">...</span> <span class="n">jarFiles</span><span class="o">)</span></code></pre></figure>

    <p>一般来说， 你只需要调用 <code>getExecutionEnvironment()</code>，因为 Flink 会根据不同的上下文来做对应的事情，比如你是在一个 IDE 中，或是作为一个常规的 Java 程序来执行 Flink 程序，那么它会创建一个本地环境，即在本地机器上执行你的程序。如果你编译了一个 JAR 文件出来，并通过 <a href="/1.1.0/apis/cli.html">命令行</a> 提交，那么 Flink 集群 manager 会执行你的 main 方法，而 <code>getExecutionEnvironment()</code> 会返回一个集群环境，即在集群上执行你的程序。</p>

    <p>执行环境（execution environment）有多种读取文件的方法用来指定数据源：可以一行一行来读取，比如csv文件， 或使用自定义的输入格式。 可以通过下列方式，来按行来读取一个文本文件：</p>

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="kd">final</span> <span class="n">StreamExecutionEnvironment</span> <span class="n">env</span> <span class="o">=</span> <span class="n">StreamExecutionEnvironment</span><span class="o">.</span><span class="na">getExecutionEnvironment</span><span class="o">();</span>

<span class="n">DataStream</span><span class="o">&lt;</span><span class="n">String</span><span class="o">&gt;</span> <span class="n">text</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="na">readTextFile</span><span class="o">(</span><span class="s">&quot;file:///path/to/file&quot;</span><span class="o">);</span></code></pre></figure>

    <p>通过这种方式你就能得到一个 DataStream，在这之上你可以接着应用一些转换来得到衍生的 DataStream。</p>

    <p>你可以通过调用 DataStream 上的转换函数来应用转换。例如，一个 map 转换看起来是这样的：</p>

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="n">DataStream</span><span class="o">&lt;</span><span class="n">String</span><span class="o">&gt;</span> <span class="n">input</span> <span class="o">=</span> <span class="o">...;</span>

<span class="n">DataStream</span><span class="o">&lt;</span><span class="n">Integer</span><span class="o">&gt;</span> <span class="n">parsed</span> <span class="o">=</span> <span class="n">input</span><span class="o">.</span><span class="na">map</span><span class="o">(</span><span class="k">new</span> <span class="n">MapFunction</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">Integer</span><span class="o">&gt;()</span> <span class="o">{</span>
    <span class="nd">@Override</span>
    <span class="kd">public</span> <span class="n">Integer</span> <span class="nf">map</span><span class="o">(</span><span class="n">String</span> <span class="n">value</span><span class="o">)</span> <span class="o">{</span>
        <span class="k">return</span> <span class="n">Integer</span><span class="o">.</span><span class="na">parseInt</span><span class="o">(</span><span class="n">value</span><span class="o">);</span>
    <span class="o">}</span>
<span class="o">});</span></code></pre></figure>

    <p>这会创建一个新的 DataStream，其中原始集合中的每一个 String 都被转换成了 Integer。</p>

    <p>一旦你得到了一个包含最终结果的 DataStream，你就可以通过创建一个 sink 将它写入到外部系统中。以下是一些创建 sink 的方法例子：</p>

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="n">writeAsText</span><span class="o">(</span><span class="n">String</span> <span class="n">path</span><span class="o">)</span>

<span class="n">print</span><span class="o">()</span></code></pre></figure>

  </div>
  <div data-lang="scala">

    <p>现在，我们将大致介绍下每一步，你可以参考相应的章节了解更多。注意所有的 Scala DataSet API 核心类都可以在 <a href="https://github.com/apache/flink/blob/master//flink-scala/src/main/scala/org/apache/flink/api/scala">org.apache.flink.api.scala</a> 中找到，而所有的 Scala DataStream API 核心类可以在 <a href="https://github.com/apache/flink/blob/master//flink-streaming-scala/src/main/java/org/apache/flink/streaming/api/scala">org.apache.flink.streaming.api.scala</a> 中找到。</p>

    <p><code>StreamExecutionEnvironment</code> 是所有 Flink 程序的基础，你可以使用 <code>StreamExecutionEnvironment</code> 中的这些静态方法来获得：</p>

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="n">getExecutionEnvironment</span><span class="o">()</span>

<span class="n">createLocalEnvironment</span><span class="o">()</span>

<span class="n">createRemoteEnvironment</span><span class="o">(</span><span class="n">host</span><span class="k">:</span> <span class="kt">String</span><span class="o">,</span> <span class="n">port</span><span class="k">:</span> <span class="kt">Int</span><span class="o">,</span> <span class="n">jarFiles</span><span class="k">:</span> <span class="kt">String*</span><span class="o">)</span></code></pre></figure>

    <p>一般来说， 你只需要调用 <code>getExecutionEnvironment()</code>，因为 Flink 会根据不同的上下文来做对应的事情，比如你是在一个 IDE 中，或是作为一个常规的 Java 程序来执行 Flink 程序，那么它会创建一个本地环境，即在本地机器上执行你的程序。如果你编译了一个 JAR 文件出来，并通过 <a href="/1.1.0/apis/cli.html">命令行</a> 提交，那么 Flink 集群 manager 会执行你的 main 方法，而 <code>getExecutionEnvironment()</code> 会返回一个集群环境，即在集群上执行你的程序。</p>

    <p>执行环境（execution environment）有多种读取文件的方法用来指定数据源：可以一行一行来读取，比如csv文件， 或使用自定义的输入格式。 可以通过下列方式，来按行来读取一个文本文件：</p>

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">env</span> <span class="k">=</span> <span class="nc">StreamExecutionEnvironment</span><span class="o">.</span><span class="n">getExecutionEnvironment</span><span class="o">()</span>

<span class="k">val</span> <span class="n">text</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[</span><span class="kt">String</span><span class="o">]</span> <span class="k">=</span> <span class="n">env</span><span class="o">.</span><span class="n">readTextFile</span><span class="o">(</span><span class="s">&quot;file:///path/to/file&quot;</span><span class="o">)</span></code></pre></figure>

    <p>通过这种方式你就能得到一个 DataStream，在这之上你可以接着应用一些转换来得到衍生的 DataStream。</p>

    <p>你可以通过调用 DataStream 上的转换函数来应用转换。例如，一个 map 转换看起来是这样的：</p>

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">input</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[</span><span class="kt">String</span><span class="o">]</span> <span class="k">=</span> <span class="o">...</span>

<span class="k">val</span> <span class="n">mapped</span> <span class="k">=</span> <span class="n">input</span><span class="o">.</span><span class="n">map</span> <span class="o">{</span> <span class="n">x</span> <span class="k">=&gt;</span> <span class="n">x</span><span class="o">.</span><span class="n">toInt</span> <span class="o">}</span></code></pre></figure>

    <p>这会创建一个新的 DataStream，其中原始集合中的每一个 String 都被转换成了 Integer。</p>

    <p>一旦你得到了一个包含最终结果的 DataStream，你就可以通过创建一个 sink 将它写入到外部系统中。以下是一些创建 sink 的方法例子：</p>

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="n">writeAsText</span><span class="o">(</span><span class="n">path</span><span class="k">:</span> <span class="kt">String</span><span class="o">)</span>

<span class="n">print</span><span class="o">()</span></code></pre></figure>

  </div>
</div>

<p>一旦完成程序，用户需要<strong>启动程序执行</strong>，可以直接调用 <code>StreamExecutionEnviroment</code> 的 <code>execute()</code>， 根据不同的 <code>ExecutionEnvironment</code> 类型，将会决定本地模式执行或是提交到集群上执行。</p>

<p><code>execute()</code> 函数会返回 <code>JobExecutionResult</code>，包含执行的次数和累加器（accumulator）结果。</p>

<p>请查阅 <a href="/1.1.0/apis/streaming/index.html">Streaming 指南</a> 了解更多关于流数据源、sink、以及关于 DataStream 所支持转换（transformations）的更深入的信息。</p>

<p>请查阅 <a href="/1.1.0/apis/batch/index.html">Batch 指南</a> 了解更多关于批数据源、sink、以及关于 DataSet 所支持转换（transformations）的更深入的信息。</p>

<p><a href="#top" class="top pull-right"><span class="glyphicon glyphicon-chevron-up"></span> Back to top</a></p>

<h2 id="延迟计算lazy-evaluation">延迟计算（Lazy Evaluation）</h2>

<p>所有的 Flink 程序都是延迟执行的：当执行程序的 main 函数时，数据加载了但转换并没有马上执行。相反，每个操作都被创建并加入到了程序执行计划中。当调用 <code>ExecutionEnvironment</code> 的 <code>execute()</code> 时，这些操作才被真正执行。程序是本地执行还是分布式执行取决于执行环境。</p>

<p>延迟计算的机制可以让你能构建复杂的程序，而 Flink 仍会视为一个整体计划执行。</p>

<p><a href="#top" class="top pull-right"><span class="glyphicon glyphicon-chevron-up"></span> Back to top</a></p>

<p><a id="specifying-keys"></a></p>

<h2 id="指定-keys">指定 Keys</h2>

<p>一些转换（join，coGroup，keyBy，groupBy）需要在数据集上定义一个 key 。另外一些转换（Reduce，GroupReduce，Aggregate，Window）允许应用在根据 key 分组的数据上（如 KeyedStream）。</p>

<p>一个 DataSet 可以如下这样被分组：</p>

<figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="n">DataSet</span><span class="o">&lt;...&gt;</span> <span class="n">input</span> <span class="o">=</span> <span class="c1">// [...]</span>
<span class="n">DataSet</span><span class="o">&lt;...&gt;</span> <span class="n">reduced</span> <span class="o">=</span> <span class="n">input</span>
  <span class="o">.</span><span class="na">groupBy</span><span class="o">(</span><span class="cm">/*define key here*/</span><span class="o">)</span>
  <span class="o">.</span><span class="na">reduceGroup</span><span class="o">(</span><span class="cm">/*do something*/</span><span class="o">);</span></code></pre></figure>

<p>而在 DataStream 上指定一个 key 时需要：</p>

<figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="n">DataStream</span><span class="o">&lt;...&gt;</span> <span class="n">input</span> <span class="o">=</span> <span class="c1">// [...]</span>
<span class="n">DataStream</span><span class="o">&lt;...&gt;</span> <span class="n">windowed</span> <span class="o">=</span> <span class="n">input</span>
  <span class="o">.</span><span class="na">key</span><span class="o">(</span><span class="cm">/*define key here*/</span><span class="o">)</span>
  <span class="o">.</span><span class="na">window</span><span class="o">(</span><span class="cm">/*window specification*/</span><span class="o">);</span></code></pre></figure>

<p>Flink 的数据模型并不是基于键值对的。因此，你不需要把数据类型转换成 keys/values。Key 实际上是“虚拟”的：它们被定义为实际数据上的函数，用来引导分组操作（grouping operator）。</p>

<p><strong>注意：</strong>在下面的讨论中我们会使用 <code>DataStream</code> API 和 <code>keyBy</code>。对于 DataSet API 你只需要替换成 <code>DataSet</code> 和  <code>groupBy</code>。</p>

<h3 class="no_toc" id="为-tuple-定义-key">为 Tuple 定义 key</h3>

<p>最简单的例子是，在一个或多个字段上对一组 Tuples 进行 grouping：</p>

<div class="codetabs">
  <div data-lang="java">

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="n">DataStream</span><span class="o">&lt;</span><span class="n">Tuple3</span><span class="o">&lt;</span><span class="n">Integer</span><span class="o">,</span><span class="n">String</span><span class="o">,</span><span class="n">Long</span><span class="o">&gt;&gt;</span> <span class="n">input</span> <span class="o">=</span> <span class="c1">// [...]</span>
<span class="n">KeyedStream</span><span class="o">&lt;</span><span class="n">Tuple3</span><span class="o">&lt;</span><span class="n">Integer</span><span class="o">,</span><span class="n">String</span><span class="o">,</span><span class="n">Long</span><span class="o">&gt;</span> <span class="n">keyed</span> <span class="o">=</span> <span class="n">input</span><span class="o">.</span><span class="na">keyBy</span><span class="o">(</span><span class="mi">0</span><span class="o">)</span></code></pre></figure>

  </div>
  <div data-lang="scala">

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">input</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[(</span><span class="kt">Int</span>, <span class="kt">String</span>, <span class="kt">Long</span><span class="o">)]</span> <span class="k">=</span> <span class="c1">// [...]</span>
<span class="k">val</span> <span class="n">keyed</span> <span class="k">=</span> <span class="n">input</span><span class="o">.</span><span class="n">keyBy</span><span class="o">(</span><span class="mi">0</span><span class="o">)</span></code></pre></figure>

  </div>
</div>

<p>这组 Tuples 是在第一个字段上进行分组的（Integer 类型的那个）。</p>

<div class="codetabs">
  <div data-lang="java">

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="n">DataStream</span><span class="o">&lt;</span><span class="n">Tuple3</span><span class="o">&lt;</span><span class="n">Integer</span><span class="o">,</span><span class="n">String</span><span class="o">,</span><span class="n">Long</span><span class="o">&gt;&gt;</span> <span class="n">input</span> <span class="o">=</span> <span class="c1">// [...]</span>
<span class="n">KeyedStream</span><span class="o">&lt;</span><span class="n">Tuple3</span><span class="o">&lt;</span><span class="n">Integer</span><span class="o">,</span><span class="n">String</span><span class="o">,</span><span class="n">Long</span><span class="o">&gt;</span> <span class="n">keyed</span> <span class="o">=</span> <span class="n">input</span><span class="o">.</span><span class="na">keyBy</span><span class="o">(</span><span class="mi">0</span><span class="o">,</span><span class="mi">1</span><span class="o">)</span></code></pre></figure>

  </div>
  <div data-lang="scala">

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">input</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[(</span><span class="kt">Int</span>, <span class="kt">String</span>, <span class="kt">Long</span><span class="o">)]</span> <span class="k">=</span> <span class="c1">// [...]</span>
<span class="k">val</span> <span class="n">grouped</span> <span class="k">=</span> <span class="n">input</span><span class="o">.</span><span class="n">groupBy</span><span class="o">(</span><span class="mi">0</span><span class="o">,</span><span class="mi">1</span><span class="o">)</span></code></pre></figure>

  </div>
</div>

<p>这里，我们在第一个和第二个字段的组合 key 上对 Tuples 进行了分组。</p>

<p>嵌套 Tuples 的注意点： 如果你有一个嵌套 tuple 的 DataStream，比如：</p>

<figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="n">DataStream</span><span class="o">&lt;</span><span class="n">Tuple3</span><span class="o">&lt;</span><span class="n">Tuple2</span><span class="o">&lt;</span><span class="n">Integer</span><span class="o">,</span> <span class="n">Float</span><span class="o">&gt;,</span><span class="n">String</span><span class="o">,</span><span class="n">Long</span><span class="o">&gt;&gt;</span> <span class="n">ds</span><span class="o">;</span></code></pre></figure>

<p>指定 <code>keyBy(0)</code>，系统会使用整个 <code>Tuple2</code> 作为一个 key （Integer 和 Float 字段同时作为 key）。如果你想要“导航”到嵌套 <code>Tuple2</code> 里，你还得使用字段表达式，下面将会讲到。</p>

<h3 class="no_toc" id="使用字段表达式定义-key">使用字段表达式定义 Key</h3>

<p>你可以使用基于 String 的字段表达式来引用嵌套字段并定义 keys，用来做 grouping, sorting, joining, 或 coGrouping。</p>

<p>字段表达式使得在（嵌套的）组合类型中选择字段变得非常方便，比如 <a href="#tuples-and-case-classes">Tuple</a> 和 <a href="#pojos">POJO</a> 类型.</p>

<div class="codetabs">
  <div data-lang="java">

    <p>下面的例子中，我们有一个 <code>WC</code> POJO，带有两个字段 “word” 和 “count”。要按照 <code>word</code> 字段来分组，我们只需要将它的名字传到 <code>groupBy()</code> 函数中。</p>

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="c1">// some ordinary POJO (Plain old Java Object)</span>
<span class="kd">public</span> <span class="kd">class</span> <span class="nc">WC</span> <span class="o">{</span>
  <span class="kd">public</span> <span class="n">String</span> <span class="n">word</span><span class="o">;</span>
  <span class="kd">public</span> <span class="kt">int</span> <span class="n">count</span><span class="o">;</span>
<span class="o">}</span>
<span class="n">DataStream</span><span class="o">&lt;</span><span class="n">WC</span><span class="o">&gt;</span> <span class="n">words</span> <span class="o">=</span> <span class="c1">// [...]</span>
<span class="n">DataStream</span><span class="o">&lt;</span><span class="n">WC</span><span class="o">&gt;</span> <span class="n">wordCounts</span> <span class="o">=</span> <span class="n">words</span><span class="o">.</span><span class="na">keyBy</span><span class="o">(</span><span class="s">&quot;word&quot;</span><span class="o">).</span><span class="na">window</span><span class="o">(</span><span class="cm">/*window specification*/</span><span class="o">);</span></code></pre></figure>

    <p><strong>字段表达式语法</strong>:</p>

    <ul>
      <li>
        <p>通过字段名来选择 POJO 中的字段。例如 <code>"user"</code> 就代表 WC POJO 中的 “user” 字段。</p>
      </li>
      <li>
        <p>通过字段名或者从 0 偏移的字段索引来选择 Tuple 中的字段。例如 <code>"f0"</code> 和 <code>"5"</code> 就分别代表了一个 Java Tuple 类中的第一个和第六个字段。</p>
      </li>
      <li>
        <p>你可以在 POJOs 和 Tuples 中选择嵌套的字段。例如，<code>"user.zip"</code> 代表了一个 POJO 类型中的 “user” 字段中的 “zip” 字段，其中 “user” 也是 POJO 类型。也支持任意嵌套以及 POJOs 与 Tuples 的混合，如 <code>"f1.user.zip"</code> 或 <code>"user.f3.1.zip"</code>。</p>
      </li>
      <li>
        <p>你可以使用 <code>"*"</code> 通配符来选择全部类型。这对于不是 Tuple 和 POJO 类型的也同样适用。</p>
      </li>
    </ul>

    <p><strong>字段表达式实例</strong>:</p>

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="kd">public</span> <span class="kd">static</span> <span class="kd">class</span> <span class="nc">WC</span> <span class="o">{</span>
  <span class="kd">public</span> <span class="n">ComplexNestedClass</span> <span class="n">complex</span><span class="o">;</span> <span class="c1">//nested POJO</span>
  <span class="kd">private</span> <span class="kt">int</span> <span class="n">count</span><span class="o">;</span>
  <span class="c1">// getter / setter for private field (count)</span>
  <span class="kd">public</span> <span class="kt">int</span> <span class="nf">getCount</span><span class="o">()</span> <span class="o">{</span>
    <span class="k">return</span> <span class="n">count</span><span class="o">;</span>
  <span class="o">}</span>
  <span class="kd">public</span> <span class="kt">void</span> <span class="nf">setCount</span><span class="o">(</span><span class="kt">int</span> <span class="n">c</span><span class="o">)</span> <span class="o">{</span>
    <span class="k">this</span><span class="o">.</span><span class="na">count</span> <span class="o">=</span> <span class="n">c</span><span class="o">;</span>
  <span class="o">}</span>
<span class="o">}</span>
<span class="kd">public</span> <span class="kd">static</span> <span class="kd">class</span> <span class="nc">ComplexNestedClass</span> <span class="o">{</span>
  <span class="kd">public</span> <span class="n">Integer</span> <span class="n">someNumber</span><span class="o">;</span>
  <span class="kd">public</span> <span class="kt">float</span> <span class="n">someFloat</span><span class="o">;</span>
  <span class="kd">public</span> <span class="n">Tuple3</span><span class="o">&lt;</span><span class="n">Long</span><span class="o">,</span> <span class="n">Long</span><span class="o">,</span> <span class="n">String</span><span class="o">&gt;</span> <span class="n">word</span><span class="o">;</span>
  <span class="kd">public</span> <span class="n">IntWritable</span> <span class="n">hadoopCitizen</span><span class="o">;</span>
<span class="o">}</span></code></pre></figure>

    <p>对于上面的实例代码，这些字段表达式都是合法的：</p>

    <ul>
      <li>
        <p><code>"count"</code>: 指 WC 类中的 <code>count</code> 字段。</p>
      </li>
      <li>
        <p><code>"complex"</code>: 递归选择了 POJO 类型 <code>ComplexNestedClass</code> 的所有字段。</p>
      </li>
      <li>
        <p><code>"complex.word.f2"</code>: 选择了嵌套的 <code>Tuple3</code> 中的最后一个字段。</p>
      </li>
      <li>
        <p><code>"complex.hadoopCitizen"</code>: 选择了这个 Hadoop <code>IntWritable</code> 类型的字段。</p>
      </li>
    </ul>

  </div>
  <div data-lang="scala">

    <p>下面的例子中，我们有一个 <code>WC</code> POJO，带有两个字段 “word” 和 “count”。要按照 <code>word</code> 字段来分组，我们只需要将它的名字传到 <code>groupBy()</code> 函数中。</p>

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="c1">// some ordinary POJO (Plain old Java Object)</span>
<span class="kd">class</span> <span class="nf">WC</span><span class="o">(</span><span class="n">var</span> <span class="nl">word:</span> <span class="n">String</span><span class="o">,</span> <span class="n">var</span> <span class="nl">count:</span> <span class="n">Int</span><span class="o">)</span> <span class="o">{</span>
  <span class="n">def</span> <span class="nf">this</span><span class="o">()</span> <span class="o">{</span> <span class="k">this</span><span class="o">(</span><span class="s">&quot;&quot;</span><span class="o">,</span> <span class="mi">0L</span><span class="o">)</span> <span class="o">}</span>
<span class="o">}</span>
<span class="n">val</span> <span class="nl">words:</span> <span class="n">DataStream</span><span class="o">[</span><span class="n">WC</span><span class="o">]</span> <span class="o">=</span> <span class="c1">// [...]</span>
<span class="n">val</span> <span class="n">wordCounts</span> <span class="o">=</span> <span class="n">words</span><span class="o">.</span><span class="na">keyBy</span><span class="o">(</span><span class="s">&quot;word&quot;</span><span class="o">).</span><span class="na">window</span><span class="o">(</span><span class="cm">/*window specification*/</span><span class="o">)</span>

<span class="c1">// or, as a case class, which is less typing</span>
<span class="k">case</span> <span class="kd">class</span> <span class="nf">WC</span><span class="o">(</span><span class="nl">word:</span> <span class="n">String</span><span class="o">,</span> <span class="nl">count:</span> <span class="n">Int</span><span class="o">)</span>
<span class="n">val</span> <span class="nl">words:</span> <span class="n">DataStream</span><span class="o">[</span><span class="n">WC</span><span class="o">]</span> <span class="o">=</span> <span class="c1">// [...]</span>
<span class="n">val</span> <span class="n">wordCounts</span> <span class="o">=</span> <span class="n">words</span><span class="o">.</span><span class="na">keyBy</span><span class="o">(</span><span class="s">&quot;word&quot;</span><span class="o">).</span><span class="na">reduce</span><span class="o">(</span><span class="cm">/*window specification*/</span><span class="o">)</span></code></pre></figure>

    <p><strong>字段表达式语法</strong>:</p>

    <ul>
      <li>
        <p>通过字段名来选择 POJO 中的字段。例如 <code>"user"</code> 就代表 WC POJO 中的 “user” 字段。</p>
      </li>
      <li>
        <p>通过从 1 偏移的字段名或者从 0 偏移的字段索引来选择 Tuple 中的字段。例如 <code>"_1"</code> 和 <code>"5"</code> 就分别代表了一个 Java Tuple 类中的第一个和第六个字段。</p>
      </li>
      <li>
        <p>你可以在 POJOs 和 Tuples 中选择嵌套的字段。例如，<code>"user.zip"</code> 代表了一个 POJO 类型中的 “user” 字段中的 “zip” 字段，其中 “user” 也是 POJO 类型。也支持任意嵌套以及 POJOs 与 Tuples 的混合，如 <code>"_2.user.zip"</code> 或 <code>"user._4.1.zip"</code>。</p>
      </li>
      <li>
        <p>你可以使用 <code>"_"</code> 通配符来选择全部类型。这对于不是 Tuple 和 POJO 类型的也同样适用。</p>
      </li>
    </ul>

    <p><strong>字段表达式实例</strong>:</p>

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">class</span> <span class="nc">WC</span><span class="o">(</span><span class="k">var</span> <span class="n">complex</span><span class="k">:</span> <span class="kt">ComplexNestedClass</span><span class="o">,</span> <span class="k">var</span> <span class="n">count</span><span class="k">:</span> <span class="kt">Int</span><span class="o">)</span> <span class="o">{</span>
  <span class="k">def</span> <span class="k">this</span><span class="o">()</span> <span class="o">{</span> <span class="k">this</span><span class="o">(</span><span class="kc">null</span><span class="o">,</span> <span class="mi">0</span><span class="o">)</span> <span class="o">}</span>
<span class="o">}</span>

<span class="k">class</span> <span class="nc">ComplexNestedClass</span><span class="o">(</span>
    <span class="k">var</span> <span class="n">someNumber</span><span class="k">:</span> <span class="kt">Int</span><span class="o">,</span>
    <span class="n">someFloat</span><span class="k">:</span> <span class="kt">Float</span><span class="o">,</span>
    <span class="n">word</span><span class="k">:</span> <span class="o">(</span><span class="kt">Long</span><span class="o">,</span> <span class="kt">Long</span><span class="o">,</span> <span class="nc">String</span><span class="o">),</span>
    <span class="n">hadoopCitizen</span><span class="k">:</span> <span class="kt">IntWritable</span><span class="o">)</span> <span class="o">{</span>
  <span class="k">def</span> <span class="k">this</span><span class="o">()</span> <span class="o">{</span> <span class="k">this</span><span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="mi">0</span><span class="o">,</span> <span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="mi">0</span><span class="o">,</span> <span class="s">&quot;&quot;</span><span class="o">),</span> <span class="k">new</span> <span class="nc">IntWritable</span><span class="o">(</span><span class="mi">0</span><span class="o">))</span> <span class="o">}</span>
<span class="o">}</span></code></pre></figure>

    <p>对于上面的实例代码，这些字段表达式都是合法的：</p>

    <ul>
      <li>
        <p><code>"count"</code>: 指 WC 类中的 <code>count</code> 字段。</p>
      </li>
      <li>
        <p><code>"complex"</code>: 递归选择了 POJO 类型 <code>ComplexNestedClass</code> 的所有字段。</p>
      </li>
      <li>
        <p><code>"complex.word._3"</code>: 选择了嵌套的 <code>Tuple3</code> 中的最后一个字段。</p>
      </li>
      <li>
        <p><code>"complex.hadoopCitizen"</code>: 选择了这个 Hadoop <code>IntWritable</code> 类型的字段。</p>
      </li>
    </ul>

  </div>
</div>

<h3 class="no_toc" id="使用-key-选择器函数定义-key">使用 Key 选择器函数定义 Key</h3>

<p>还有一种定义 key 的方法是 “key 选择器”（key selector） 函数。Key 选择器函数接受一个单独的元素作为输入，并返回这个元素的 key。这个 key 可以是任何类型，也可以是任意计算结果。</p>

<p>下面这个例子展示了一个 key 选择器函数：简单地返回了一个对象的字段。</p>

<div class="codetabs">
  <div data-lang="java">

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="c1">// some ordinary POJO</span>
<span class="kd">public</span> <span class="kd">class</span> <span class="nc">WC</span> <span class="o">{</span><span class="kd">public</span> <span class="n">String</span> <span class="n">word</span><span class="o">;</span> <span class="kd">public</span> <span class="kt">int</span> <span class="n">count</span><span class="o">;}</span>
<span class="n">DataStream</span><span class="o">&lt;</span><span class="n">WC</span><span class="o">&gt;</span> <span class="n">words</span> <span class="o">=</span> <span class="c1">// [...]</span>
<span class="n">KeyedStream</span><span class="o">&lt;</span><span class="n">WC</span><span class="o">&gt;</span> <span class="n">kyed</span> <span class="o">=</span> <span class="n">words</span>
  <span class="o">.</span><span class="na">keyBy</span><span class="o">(</span><span class="k">new</span> <span class="n">KeySelector</span><span class="o">&lt;</span><span class="n">WC</span><span class="o">,</span> <span class="n">String</span><span class="o">&gt;()</span> <span class="o">{</span>
     <span class="kd">public</span> <span class="n">String</span> <span class="nf">getKey</span><span class="o">(</span><span class="n">WC</span> <span class="n">wc</span><span class="o">)</span> <span class="o">{</span> <span class="k">return</span> <span class="n">wc</span><span class="o">.</span><span class="na">word</span><span class="o">;</span> <span class="o">}</span>
   <span class="o">});</span></code></pre></figure>

  </div>
  <div data-lang="scala">

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="c1">// some ordinary case class</span>
<span class="k">case</span> <span class="k">class</span> <span class="nc">WC</span><span class="o">(</span><span class="n">word</span><span class="k">:</span> <span class="kt">String</span><span class="o">,</span> <span class="n">count</span><span class="k">:</span> <span class="kt">Int</span><span class="o">)</span>
<span class="k">val</span> <span class="n">words</span><span class="k">:</span> <span class="kt">DataStream</span><span class="o">[</span><span class="kt">WC</span><span class="o">]</span> <span class="k">=</span> <span class="c1">// [...]</span>
<span class="k">val</span> <span class="n">keyed</span> <span class="k">=</span> <span class="n">words</span><span class="o">.</span><span class="n">keyBy</span><span class="o">(</span> <span class="k">_</span><span class="o">.</span><span class="n">word</span> <span class="o">)</span></code></pre></figure>

  </div>
</div>

<p><a href="#top" class="top pull-right"><span class="glyphicon glyphicon-chevron-up"></span> Back to top</a></p>

<h2 id="定义转换函数">定义转换函数</h2>

<p>大部分转换都需要一个用户实现的函数。这一节就如何定义转换函数列出了一些不同的方法。</p>

<div class="codetabs">
  <div data-lang="java">

    <h4 id="section">实现接口</h4>

    <p>最常见的方式是实现一个 Flink 提供的接口：</p>

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="kd">class</span> <span class="nc">MyMapFunction</span> <span class="kd">implements</span> <span class="n">MapFunction</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">Integer</span><span class="o">&gt;</span> <span class="o">{</span>
  <span class="kd">public</span> <span class="n">Integer</span> <span class="nf">map</span><span class="o">(</span><span class="n">String</span> <span class="n">value</span><span class="o">)</span> <span class="o">{</span> <span class="k">return</span> <span class="n">Integer</span><span class="o">.</span><span class="na">parseInt</span><span class="o">(</span><span class="n">value</span><span class="o">);</span> <span class="o">}</span>
<span class="o">});</span>
<span class="n">data</span><span class="o">.</span><span class="na">map</span><span class="o">(</span><span class="k">new</span> <span class="nf">MyMapFunction</span><span class="o">());</span></code></pre></figure>

    <h4 id="section-1">匿名类</h4>

    <p>以匿名类的形式传入一个函数：</p>

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="n">data</span><span class="o">.</span><span class="na">map</span><span class="o">(</span><span class="k">new</span> <span class="n">MapFunction</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">Integer</span><span class="o">&gt;</span> <span class="o">()</span> <span class="o">{</span>
  <span class="kd">public</span> <span class="n">Integer</span> <span class="nf">map</span><span class="o">(</span><span class="n">String</span> <span class="n">value</span><span class="o">)</span> <span class="o">{</span> <span class="k">return</span> <span class="n">Integer</span><span class="o">.</span><span class="na">parseInt</span><span class="o">(</span><span class="n">value</span><span class="o">);</span> <span class="o">}</span>
<span class="o">});</span></code></pre></figure>

    <h4 id="java-8-lambdas">Java 8 Lambdas</h4>

    <p>Flink 在 Java API 中也支持了 Java 8 Lambdas。请参考完整的 <a href="/1.1.0/apis/java8.html">Java 8 指南</a>。</p>

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="n">data</span><span class="o">.</span><span class="na">filter</span><span class="o">(</span><span class="n">s</span> <span class="o">-&gt;</span> <span class="n">s</span><span class="o">.</span><span class="na">startsWith</span><span class="o">(</span><span class="s">&quot;http://&quot;</span><span class="o">));</span></code></pre></figure>

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="n">data</span><span class="o">.</span><span class="na">reduce</span><span class="o">((</span><span class="n">i1</span><span class="o">,</span><span class="n">i2</span><span class="o">)</span> <span class="o">-&gt;</span> <span class="n">i1</span> <span class="o">+</span> <span class="n">i2</span><span class="o">);</span></code></pre></figure>

    <h4 id="section-2">富函数</h4>

    <p>所有转换中需要的用户自定义函数都可以被替换成<em>富</em>函数（rich function）作为参数。例如，代替</p>

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="kd">class</span> <span class="nc">MyMapFunction</span> <span class="kd">implements</span> <span class="n">MapFunction</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">Integer</span><span class="o">&gt;</span> <span class="o">{</span>
  <span class="kd">public</span> <span class="n">Integer</span> <span class="nf">map</span><span class="o">(</span><span class="n">String</span> <span class="n">value</span><span class="o">)</span> <span class="o">{</span> <span class="k">return</span> <span class="n">Integer</span><span class="o">.</span><span class="na">parseInt</span><span class="o">(</span><span class="n">value</span><span class="o">);</span> <span class="o">}</span>
<span class="o">});</span></code></pre></figure>

    <p>你可以写成</p>

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="kd">class</span> <span class="nc">MyMapFunction</span> <span class="kd">extends</span> <span class="n">RichMapFunction</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">Integer</span><span class="o">&gt;</span> <span class="o">{</span>
  <span class="kd">public</span> <span class="n">Integer</span> <span class="nf">map</span><span class="o">(</span><span class="n">String</span> <span class="n">value</span><span class="o">)</span> <span class="o">{</span> <span class="k">return</span> <span class="n">Integer</span><span class="o">.</span><span class="na">parseInt</span><span class="o">(</span><span class="n">value</span><span class="o">);</span> <span class="o">}</span>
<span class="o">});</span></code></pre></figure>

    <p>然后，与之前一样，将这个函数传到 <code>map</code> 转换中：</p>

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="n">data</span><span class="o">.</span><span class="na">map</span><span class="o">(</span><span class="k">new</span> <span class="nf">MyMapFunction</span><span class="o">());</span></code></pre></figure>

    <p>富函数同样可以被定义成匿名类：</p>

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="n">data</span><span class="o">.</span><span class="na">map</span> <span class="o">(</span><span class="k">new</span> <span class="n">RichMapFunction</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">Integer</span><span class="o">&gt;()</span> <span class="o">{</span>
  <span class="kd">public</span> <span class="n">Integer</span> <span class="nf">map</span><span class="o">(</span><span class="n">String</span> <span class="n">value</span><span class="o">)</span> <span class="o">{</span> <span class="k">return</span> <span class="n">Integer</span><span class="o">.</span><span class="na">parseInt</span><span class="o">(</span><span class="n">value</span><span class="o">);</span> <span class="o">}</span>
<span class="o">});</span></code></pre></figure>

  </div>
  <div data-lang="scala">

    <h4 id="lambda-">Lambda 函数</h4>

    <p>如在上述实例中看到的，所有操作都接受了一个 lambda 函数，用来描述操作的内容：</p>

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">data</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[</span><span class="kt">String</span><span class="o">]</span> <span class="k">=</span> <span class="c1">// [...]</span>
<span class="n">data</span><span class="o">.</span><span class="n">filter</span> <span class="o">{</span> <span class="k">_</span><span class="o">.</span><span class="n">startsWith</span><span class="o">(</span><span class="s">&quot;http://&quot;</span><span class="o">)</span> <span class="o">}</span></code></pre></figure>

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">data</span><span class="k">:</span> <span class="kt">DataSet</span><span class="o">[</span><span class="kt">Int</span><span class="o">]</span> <span class="k">=</span> <span class="c1">// [...]</span>
<span class="n">data</span><span class="o">.</span><span class="n">reduce</span> <span class="o">{</span> <span class="o">(</span><span class="n">i1</span><span class="o">,</span><span class="n">i2</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="n">i1</span> <span class="o">+</span> <span class="n">i2</span> <span class="o">}</span>
<span class="c1">// or</span>
<span class="n">data</span><span class="o">.</span><span class="n">reduce</span> <span class="o">{</span> <span class="k">_</span> <span class="o">+</span> <span class="k">_</span> <span class="o">}</span></code></pre></figure>

    <h4 id="section-3">富函数</h4>

    <p>所有转换中需要的用户自定义函数都可以被替换成<em>富</em>函数（rich function）作为参数。例如，代替</p>

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="n">data</span><span class="o">.</span><span class="n">map</span> <span class="o">{</span> <span class="n">x</span> <span class="k">=&gt;</span> <span class="n">x</span><span class="o">.</span><span class="n">toInt</span> <span class="o">}</span></code></pre></figure>

    <p>你可以写成</p>

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">class</span> <span class="nc">MyMapFunction</span> <span class="k">extends</span> <span class="nc">RichMapFunction</span><span class="o">[</span><span class="kt">String</span>, <span class="kt">Int</span><span class="o">]</span> <span class="o">{</span>
  <span class="k">def</span> <span class="n">map</span><span class="o">(</span><span class="n">in</span><span class="k">:</span> <span class="kt">String</span><span class="o">)</span><span class="k">:</span><span class="kt">Int</span> <span class="o">=</span> <span class="o">{</span> <span class="n">in</span><span class="o">.</span><span class="n">toInt</span> <span class="o">}</span>
<span class="o">})</span></code></pre></figure>

    <p>然后，与之前一样，将这个函数传到 <code>map</code> 转换中：</p>

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="n">data</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="k">new</span> <span class="nc">MyMapFunction</span><span class="o">())</span></code></pre></figure>

    <p>富函数同样可以被定义成匿名类：</p>

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="n">data</span><span class="o">.</span><span class="n">map</span> <span class="o">(</span><span class="k">new</span> <span class="nc">RichMapFunction</span><span class="o">[</span><span class="kt">String</span>, <span class="kt">Int</span><span class="o">]</span> <span class="o">{</span>
  <span class="k">def</span> <span class="n">map</span><span class="o">(</span><span class="n">in</span><span class="k">:</span> <span class="kt">String</span><span class="o">)</span><span class="k">:</span><span class="kt">Int</span> <span class="o">=</span> <span class="o">{</span> <span class="n">in</span><span class="o">.</span><span class="n">toInt</span> <span class="o">}</span>
<span class="o">})</span></code></pre></figure>

  </div>
</div>

<p>除了给用户自定义的函数外（如 map、reduce 等），富函数还提供了四种函数：<code>open</code>, <code>close</code>, <code>getRuntimeContext</code>，以及<code>setRuntimeContext</code>。这些对于参数化函数（参考 <a href="/1.1.0/apis/batch/index.html#passing-parameters-to-functions">给函数传参</a>)，创建和销毁本地状态，访问广播变量（参考 <a href="/1.1.0/apis/batch/index.html#broadcast-variables">广播变量</a>），以及访问运行时信息如累加器和计数器（参考 <a href="#accumulators--counters">Accumulators 和 Counters</a>），还有迭代信息（参考 <a href="/1.1.0/apis/batch/index.html#iteration-operators">迭代</a>）都是有很大帮助的。</p>

<p><a href="#top" class="top pull-right"><span class="glyphicon glyphicon-chevron-up"></span> Back to top</a></p>

<h2 id="支持的数据类型">支持的数据类型</h2>

<p>Flink 对于 DataSets 和 DataStream 中元素类型有一些限制。原因是系统需要分析这些类型来决定高效执行策略。</p>

<p>有 6 种不同的数据类型：</p>

<ol>
  <li><strong>Java 元组（Tuples）</strong> 和 <strong>Scala 样本类（Case Classes）</strong></li>
  <li><strong>Java POJOs</strong></li>
  <li><strong>基本类型（Primitive Types）</strong></li>
  <li><strong>一般类（Regular Classes）</strong></li>
  <li><strong>Values</strong></li>
  <li><strong>Hadoop Writables</strong></li>
  <li><strong>特殊类型（Special Types）</strong></li>
</ol>

<h4 id="元组和样本类tuples-和-case-classes">元组和样本类（Tuples 和 Case Classes）</h4>

<div class="codetabs">
  <div data-lang="java">

    <p>Tuples 是由固定数量的字段组成，字段类型可以是多样化的。Java API 提供了从 <code>Tuple1</code> 到 <code>Tuple25</code> 。Tuple 中的每一个字段都可以是任意的 Flink 类型，可以是嵌套 tuple。Tuple 的字段可以直接通过字段名（如 <code>tuple.f4</code>）或者 getter 函数（如 <code>tuple.getField(int position)</code>）来访问。字段的起始索引是 0。注意，这个和 Scala tuples 不一样，但和 Java 的通用索引是一致的。</p>

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="n">DataStream</span><span class="o">&lt;</span><span class="n">Tuple2</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">Integer</span><span class="o">&gt;&gt;</span> <span class="n">wordCounts</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="na">fromElements</span><span class="o">(</span>
    <span class="k">new</span> <span class="n">Tuple2</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">Integer</span><span class="o">&gt;(</span><span class="s">&quot;hello&quot;</span><span class="o">,</span> <span class="mi">1</span><span class="o">),</span>
    <span class="k">new</span> <span class="n">Tuple2</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">Integer</span><span class="o">&gt;(</span><span class="s">&quot;world&quot;</span><span class="o">,</span> <span class="mi">2</span><span class="o">));</span>

<span class="n">wordCounts</span><span class="o">.</span><span class="na">map</span><span class="o">(</span><span class="k">new</span> <span class="n">MapFunction</span><span class="o">&lt;</span><span class="n">Tuple2</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">Integer</span><span class="o">&gt;,</span> <span class="n">Integer</span><span class="o">&gt;()</span> <span class="o">{</span>
    <span class="nd">@Override</span>
    <span class="kd">public</span> <span class="n">String</span> <span class="nf">map</span><span class="o">(</span><span class="n">Tuple2</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">Integer</span><span class="o">&gt;</span> <span class="n">value</span><span class="o">)</span> <span class="kd">throws</span> <span class="n">Exception</span> <span class="o">{</span>
        <span class="k">return</span> <span class="n">value</span><span class="o">.</span><span class="na">f1</span><span class="o">;</span>
    <span class="o">}</span>
<span class="o">});</span>

<span class="n">wordCounts</span><span class="o">.</span><span class="na">keyBy</span><span class="o">(</span><span class="mi">0</span><span class="o">);</span> <span class="c1">// also valid .keyBy(&quot;f0&quot;)</span></code></pre></figure>

  </div>
  <div data-lang="scala">

    <p>Scala 的样本类（case classes）以及 Scala 元组（tuples，一种特殊的样本类）是包含了数量固定的各种类型的字段的复合类型。元组不能通过名称获取字段，而是使用位置下标来读取对象；而且这个下标基于 1，而不是基于 0。样本类是通过名称来获得字段。</p>

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">case</span> <span class="k">class</span> <span class="nc">WordCount</span><span class="o">(</span><span class="n">word</span><span class="k">:</span> <span class="kt">String</span><span class="o">,</span> <span class="n">count</span><span class="k">:</span> <span class="kt">Int</span><span class="o">)</span>
<span class="k">val</span> <span class="n">input</span> <span class="k">=</span> <span class="n">env</span><span class="o">.</span><span class="n">fromElements</span><span class="o">(</span>
    <span class="nc">WordCount</span><span class="o">(</span><span class="s">&quot;hello&quot;</span><span class="o">,</span> <span class="mi">1</span><span class="o">),</span>
    <span class="nc">WordCount</span><span class="o">(</span><span class="s">&quot;world&quot;</span><span class="o">,</span> <span class="mi">2</span><span class="o">))</span> <span class="c1">// Case Class Data Set</span>

<span class="n">input</span><span class="o">.</span><span class="n">keyBy</span><span class="o">(</span><span class="s">&quot;word&quot;</span><span class="o">)</span><span class="c1">// key by field expression &quot;word&quot;</span>

<span class="k">val</span> <span class="n">input2</span> <span class="k">=</span> <span class="n">env</span><span class="o">.</span><span class="n">fromElements</span><span class="o">((</span><span class="s">&quot;hello&quot;</span><span class="o">,</span> <span class="mi">1</span><span class="o">),</span> <span class="o">(</span><span class="s">&quot;world&quot;</span><span class="o">,</span> <span class="mi">2</span><span class="o">))</span> <span class="c1">// Tuple2 Data Set</span>

<span class="n">input2</span><span class="o">.</span><span class="n">keyBy</span><span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="mi">1</span><span class="o">)</span> <span class="c1">// key by field positions 0 and 1</span></code></pre></figure>

  </div>
</div>

<h4 id="pojos">POJOs</h4>

<p>如果满足下列所有条件， Java 和 Scala 类就会被当做 POJO 类型：</p>

<ul>
  <li>
    <p>类必须是 public 的</p>
  </li>
  <li>
    <p>含有无参构造函数</p>
  </li>
  <li>
    <p>所有的字段要么是 public 的，要么是可以通过 getter 和 setter 函数访问的。对于一个叫做 <code>foo</code> 的字段来说，getter 和 setter 方法必须是 <code>getFoo()</code> 和 <code>setFoo()</code>。</p>
  </li>
  <li>
    <p>所有的字段类型都能被 Flink 支持。同时，Flink 使用 <a href="http://avro.apache.org">Avro</a> 来序列化对象（如 <code>Date</code>）。</p>
  </li>
</ul>

<p>Flink 会分析 POJO 类型的结构，比如 POJO 的字段。所以 POJO 比一般类型更容易使用，而且 Flink 处理 POJO 类型会比一般类型更高效。</p>

<p>下面展示了一个带有两个 public 字段的 POJO 类型。</p>

<div class="codetabs">
  <div data-lang="java">

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="kd">public</span> <span class="kd">class</span> <span class="nc">WordWithCount</span> <span class="o">{</span>

    <span class="kd">public</span> <span class="n">String</span> <span class="n">word</span><span class="o">;</span>
    <span class="kd">public</span> <span class="kt">int</span> <span class="n">count</span><span class="o">;</span>

    <span class="kd">public</span> <span class="nf">WordWithCount</span><span class="o">()</span> <span class="o">{}</span>

    <span class="kd">public</span> <span class="nf">WordWithCount</span><span class="o">(</span><span class="n">String</span> <span class="n">word</span><span class="o">,</span> <span class="kt">int</span> <span class="n">count</span><span class="o">)</span> <span class="o">{</span>
        <span class="k">this</span><span class="o">.</span><span class="na">word</span> <span class="o">=</span> <span class="n">word</span><span class="o">;</span>
        <span class="k">this</span><span class="o">.</span><span class="na">count</span> <span class="o">=</span> <span class="n">count</span><span class="o">;</span>
    <span class="o">}</span>
<span class="o">}</span>

<span class="n">DataStream</span><span class="o">&lt;</span><span class="n">Tuple2</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">Integer</span><span class="o">&gt;&gt;</span> <span class="n">wordCounts</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="na">fromElements</span><span class="o">(</span>
    <span class="k">new</span> <span class="nf">WordWithCount</span><span class="o">(</span><span class="s">&quot;hello&quot;</span><span class="o">,</span> <span class="mi">1</span><span class="o">),</span>
    <span class="k">new</span> <span class="nf">WordWithCount</span><span class="o">(</span><span class="s">&quot;world&quot;</span><span class="o">,</span> <span class="mi">2</span><span class="o">));</span>

<span class="n">wordCounts</span><span class="o">.</span><span class="na">keyBy</span><span class="o">(</span><span class="s">&quot;word&quot;</span><span class="o">);</span> <span class="c1">// key by field expression &quot;word&quot;</span></code></pre></figure>

  </div>
  <div data-lang="scala">

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">class</span> <span class="nc">WordWithCount</span><span class="o">(</span><span class="k">var</span> <span class="n">word</span><span class="k">:</span> <span class="kt">String</span><span class="o">,</span> <span class="k">var</span> <span class="n">count</span><span class="k">:</span> <span class="kt">Int</span><span class="o">)</span> <span class="o">{</span>
    <span class="k">def</span> <span class="k">this</span><span class="o">()</span> <span class="o">{</span>
      <span class="k">this</span><span class="o">(</span><span class="kc">null</span><span class="o">,</span> <span class="o">-</span><span class="mi">1</span><span class="o">)</span>
    <span class="o">}</span>
<span class="o">}</span>

<span class="k">val</span> <span class="n">input</span> <span class="k">=</span> <span class="n">env</span><span class="o">.</span><span class="n">fromElements</span><span class="o">(</span>
    <span class="k">new</span> <span class="nc">WordWithCount</span><span class="o">(</span><span class="s">&quot;hello&quot;</span><span class="o">,</span> <span class="mi">1</span><span class="o">),</span>
    <span class="k">new</span> <span class="nc">WordWithCount</span><span class="o">(</span><span class="s">&quot;world&quot;</span><span class="o">,</span> <span class="mi">2</span><span class="o">))</span> <span class="c1">// Case Class Data Set</span>

<span class="n">input</span><span class="o">.</span><span class="n">keyBy</span><span class="o">(</span><span class="s">&quot;word&quot;</span><span class="o">)</span><span class="c1">// key by field expression &quot;word&quot;</span></code></pre></figure>

  </div>
</div>

<h4 id="基本类型primitive-types">基本类型（Primitive Types）</h4>

<p>Flink 支持所有的 Java 和 Scala 的基本类型，例如 <code>Integer</code>, <code>String</code>, 和 <code>Double</code>。</p>

<h4 id="一般类general-class-types">一般类（General Class Types）</h4>

<p>Flink 支持大部分的 Java 和 Scala 类（API 或自定义的）。对于一些不能被序列化的字段会有限制，比如文件指针，I/O 流，native
resources。一般遵守 Java Beans 惯例的类都是可以的。</p>

<p>Flink 会把没有被当做 POJO 类型（请参考上面的 POJO 要求）的都当做一般类来处理。Flink 会把它们看做黑盒子并且无法访问它们的内容（例如，高效排序）。一般类型会用序列化框架 <a href="https://github.com/EsotericSoftware/kryo">Kryo</a> 来做序列化/反序列化。</p>

<h4 id="values">Values</h4>

<p><em>Value</em> 类型定义了他们自己的序列化和反序列化方式。用户自己来实现 <code>org.apache.flinktypes.Value</code> 接口的 <code>read</code> 和 <code>write</code> 方法，而不是使用通用的序列化框架。当通用的序列化方式不高效时，选择 Value 类型是合理的。一个例子是一个数据类型以数组实现了一个稀疏向量（sparse vector）。我们知道这个数组里大部分都是零，我们可以为非零元素使用一种特殊编码，然而通用的序列化框架只会简单的写入所有的数组元素。</p>

<p>类似的，<code>org.apache.flinktypes.CopyableValue</code> 接口提供了手动内部克隆（clone）逻辑。</p>

<p>Flink 已经预定义了一批基本的 Value 类型（<code>ByteValue</code>, <code>ShortValue</code>, <code>IntValue</code>, <code>LongValue</code>, <code>FloatValue</code>, <code>DoubleValue</code>, <code>StringValue</code>, <code>CharValue</code>, <code>BooleanValue</code>）。这些类型充当了基本数据类型的可变类型：它们的值可以被修改，允许开发者重复使用这些对象来减轻 GC 的压力。</p>

<h4 id="hadoop-writables">Hadoop Writables</h4>

<p>你可以使用实现了 <code>org.apache.hadoop.Writable</code> 接口的类型。定义在 <code>write()</code> 和 <code>readFields()</code> 方法中的序列化逻辑会被用来做序列化。</p>

<h4 id="特殊类型special-types">特殊类型（Special Types）</h4>

<p>你可以使用特殊类型，包括 Scala 的 <code>Either</code>, <code>Option</code>, 和 <code>Try</code>。Flink 在 Java API 中自己实现了一个 <code>Either</code>，很像 Scala 的 <code>Either</code>，它代表一个两种可能类型的值，<em>Left</em> 或 <em>Right</em>。<code>Either</code> 在错误处理或是 operator 需要输出两种不同类型的记录的时候是非常有用的。</p>

<h4 id="类型擦除和类型诊断">类型擦除和类型诊断</h4>

<p><em>注意: 本节只与 Java 有关。</em></p>

<p>Java 编译器会在编译后扔掉很多泛型类型信息，这就是 Java 中的<em>类型擦除</em>（type erasure）。也就是说在运行时，一个对象实例是不知道它的泛型类型的。举例来说，<code>DataStream&lt;String&gt;</code> 和 <code>DataStream&lt;Long&gt;</code> 的实例对 JVM 说看起来是一样的。</p>

<p>当 Flink 准备执行程序时（当 main 函数被调用），Flink 会请求类型信息。Flink Java API 会尝试重新构造被类型擦除扔掉的类型信息，并把他们显示存到数据集和 operator 中。你可以通过调用 <code>DataStream.getType()</code> 来获取它们。这个函数返回了一个 <code>TypeInformation</code> 实例，这是 Flink 内部用来表示类型的类。</p>

<p>类型诊断（type inferrence）有它自己的限制并且在一些情况下需要程序员的“配合”。举例来说， 从集合中创建的数据集的函数，比如 <code>ExecutionEnvironment.fromCollection()</code> ，在这些函数中， 用户可以传入一个用来描叙类型的参数。但一些泛型函数比如 <code>MapFunction&lt;I, O&gt;</code> 还需要一些额外的类型信息。</p>

<p><a href="https://github.com/apache/flink/blob/master//flink-java/src/main/java/org/apache/flink/api/java/typeutils/ResultTypeQueryable.java">ResultTypeQueryable</a> 接口可以通过输入格式和函数来实现明确地告诉 API 他们的返回类型。函数的<em>输入类型</em>通常可以通过前一个操作的返回值进行判断。</p>

<h2 id="执行配置">执行配置</h2>

<p><code>StreamExecutionEnvironment</code> 中包含了 <code>ExecutionConfig</code>， <code>ExecutionConfig</code> 可以用来设定任务在运行期间的具体配置。</p>

<div class="codetabs">
  <div data-lang="java">

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="n">StreamExecutionEnvironment</span> <span class="n">env</span> <span class="o">=</span> <span class="n">StreamExecutionEnvironment</span><span class="o">.</span><span class="na">getExecutionEnvironment</span><span class="o">();</span>
<span class="n">ExecutionConfig</span> <span class="n">executionConfig</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="na">getConfig</span><span class="o">();</span></code></pre></figure>

  </div>
  <div data-lang="scala">

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">env</span> <span class="k">=</span> <span class="nc">StreamExecutionEnvironment</span><span class="o">.</span><span class="n">getExecutionEnvironment</span>
<span class="k">var</span> <span class="n">executionConfig</span> <span class="k">=</span> <span class="n">env</span><span class="o">.</span><span class="n">getConfig</span></code></pre></figure>

  </div>
</div>

<p>下面这些配置项都是可以用的：(加粗的是默认项)</p>

<ul>
  <li>
    <p><strong><code>enableClosureCleaner()</code></strong> / <code>disableClosureCleaner()</code>. 默认情况下闭包清理器（closure cleaner）是打开的。闭包清理器会清除对匿名函数的环绕类（surrounding class）的无用引用。如果关闭闭包清理器，有可能一个匿名用户函数还在引用某个环绕类，这个类通常不是可序列化的（Serializable）。这样会导致序列化组件会抛出异常。</p>
  </li>
  <li>
    <p><code>getParallelism()</code> / <code>setParallelism(int parallelism)</code> 设置任务的并发。</p>
  </li>
  <li>
    <p><code>getNumberOfExecutionRetries()</code> / <code>setNumberOfExecutionRetries(int numberOfExecutionRetries)</code> 设置失败 task 的重新执行次数。为 0 表示关闭容错。－1 表示使用系统默认值。</p>
  </li>
  <li>
    <p><code>getExecutionRetryDelay()</code> / <code>setExecutionRetryDelay(long executionRetryDelay)</code> 当一个任务失败时，设置重新运行前的等待时间，单位毫秒。延期（delay）会在 TaskManager 上所有 task 都被成功停止后才开始计时。一旦设置的延期时间到了，所有 task 开始重新运行。这个参数用来延迟重新执行是非常有用的，目的是让某些超时相关的故障场景完全浮出水面（比如断了的连接还没有完全超时）。如果立即重试，容易导致相同的故障。这个参数只有当重试执行次数大于等于 1 时，才有效。</p>
  </li>
  <li>
    <p><code>getExecutionMode()</code> / <code>setExecutionMode()</code>. 默认执行模式是 PIPELINED。 设置程序的执行模式， 这决定了数据交换是采用 batch 还是 pipeline 的方式。</p>
  </li>
  <li>
    <p><code>enableForceKryo()</code> / <strong><code>disableForceKryo()</code></strong>. 默认没有使用 Kryo。强制 GenericTypeInformation 对 POJO 使用 Kryo 序列化器，即使 Flink 可以识别它们为 POJO。某些情况下推荐使用这种方式，举例来说，当 Flink 内部序列化器不能正确处理 POJO 时。</p>
  </li>
  <li>
    <p><code>enableForceAvro()</code> / <strong><code>disableForceAvro()</code></strong>. 默认强制 Avro 是关闭的。在序列化 Avro POJO 时，强制 AvroTypeInformation 使用 Avro 序列化器代替 Kryo。</p>
  </li>
  <li>
    <p><code>enableObjectReuse()</code> / <strong><code>disableObjectReuse()</code></strong>. 默认对象是不会被重复使用的。开启对象重用，会在运行时重新使用用户的对象，这能获得更好的性能。注意如果用户在定义操作的函数时并不清楚这一行为的话，可能到导致 bug。</p>
  </li>
  <li>
    <p><strong><code>enableSysoutLogging()</code></strong> / <code>disableSysoutLogging()</code>. 默认 Jobmanager 的状态更新会打印到 <code>System.out</code>。可以通过这个配置关闭这种行为。</p>
  </li>
  <li>
    <p><code>getGlobalJobParameters()</code> / <code>setGlobalJobParameters()</code> 这个函数可以设置一个自定义的对象作为任务的全局配置。 因为 <code>ExecutionConfig</code> 在所有用户定义的函数中都是可以访问到的，这是设置全局配置的一种方便方式。</p>
  </li>
  <li>
    <p><code>addDefaultKryoSerializer(Class&lt;?&gt; type, Serializer&lt;?&gt; serializer)</code> 为一个指定类型（<code>type</code>）注册一个 Kryo 序列化实例。</p>
  </li>
  <li>
    <p><code>addDefaultKryoSerializer(Class&lt;?&gt; type, Class&lt;? extends Serializer&lt;?&gt;&gt; serializerClass)</code> 为一个指定类型（<code>type</code>）注册一个 Kryo 序列化类。</p>
  </li>
  <li>
    <p><code>registerTypeWithKryoSerializer(Class&lt;?&gt; type, Serializer&lt;?&gt; serializer)</code> 为一个指定的类型注册 以 Kryo 序列化实例。通过注册类型到 Kryo，这个类型的序列化会更高效。</p>
  </li>
  <li>
    <p><code>registerKryoType(Class&lt;?&gt; type)</code>  如果这个类型最终是用 Kryo 序列化的，那么它会在 Kryo 被注册以确保只有标签（整型 ID）会被写入。如果一个类型不是使用 Kryo 注册的，那么它的整个类名（class-name）会被序列化到每个实例中，这会导致更高的 I/O 开销。</p>
  </li>
  <li>
    <p><code>registerPojoType(Class&lt;?&gt; type)</code> 用序列化堆栈来注册给定的类型。如果这个类型最终是以 POJO 来序列化的，那么这个类型会使用 POJO 序列化器注册。如果这个类型最终是用 Kryo 被序列化，那么它会在 Kryo 被注册以确保只有标签（整型 ID）会被写入。如果一个类型不是使用 Kryo 注册的，它整个类名（class-name）会被序列化到每个实例中，这会导致更高的 I/O 开销。</p>
  </li>
</ul>

<p>注意使用 <code>registerKryoType()</code> 注册的类型是不能用于 Flink 的 Kryo 序列化实例的。</p>

<ul>
  <li><code>disableAutoTypeRegistration()</code> 自动类型注册默认是开启的。”自动类型注册”存储了用户代码中用到的所有类型（包括子类型）。</li>
</ul>

<p>在 <code>Rich*</code> 函数中可以通过 <code>getRuntimeContext()</code> 方法获得 <code>RuntimeContext</code>，从中可以访问到 <code>ExecutionConfig</code>。</p>

<p><a href="#top" class="top pull-right"><span class="glyphicon glyphicon-chevron-up"></span> Back to top</a></p>

<h2 id="程序打包和分布式执行">程序打包和分布式执行</h2>

<p>如前所述，Flink 程序使用一个 <code>remote enviroment</code> 可以运行在远程的集群环境中。同样的，程序可以打包成 JAR 来执行。程序的打包是通过 <a href="/1.1.0/apis/cli.html">命令行接口</a> 执行它们的前提条件。</p>

<h4 id="打包程序">打包程序</h4>

<p>为了支持通过命令行或 web 接口执行一个打包的 JAR 文件，一个程序必须使用通过 <code>StreamExecutionEnvironment.getExecutionEnvironment()</code> 获得的环境。当 JAR 通过命令行或 web 接口提交上去后，这个环境就会是集群模式环境。如果 Flink 程序不是通过这些接口来调用，这个环境就是本地模式环境。</p>

<p>为了打包程序，可以简单地导出所有涉及到的类到一个 JAR 文件中。这个 JAR 文件的 manifest 必须指向程序的<em>入口类</em>。最简单的方式是将 <em>main-class</em> 入口加到 mainifest 中（如 <code>main-class: org.apache.flinkexample.MyProgram</code>）。 这个 <em>main-class</em> 属性和 JVM 通过命令行 <code>java -jar pathToTheJarFile</code> 执行一个 JAR 文件找到 main 入口函数是一样的。大部分的 IDE 都提供导出 JAR 时自动添加入口函数。</p>

<h4 id="通过计划打包程序">通过计划打包程序</h4>

<p>Flink 还支持通过计划（<em>Plans</em>）来打包程序。计划打包返回的是 <em>Program Plan</em>（这是一个对程序数据流的描述），而不是在 main 函数中定义程序并在环境上调用 <code>execute()</code>。因此，程序必须实现 <code>org.apache.flink.api.common.Program</code> 接口，定义 <code>getPlan(String...)</code> 方法。传递给这个函数的 String 列表就是命令行参数。这个程序的计划可以通过 <code>ExecutionEnvironment#createProgramPlan()</code> 来创建出来。当打包这个程序的计划时，这个 JAR 的 mainfest 必须指向实现 <code>org.apache.flinkapi.common.Program</code> 接口的类，而不是带 main 入口函数的类。</p>

<h4 id="总结">总结</h4>

<p>调用一个打包的程序的整体流程如下：</p>

<ol>
  <li>
    <p>搜索 JAR 的 manifest 找到 <em>main-class</em> 或 <em>program－class</em>。如果这两个属性都被找到了，则 <em>program-class</em> 属性优先考虑。 当 JAR 的 manifest 两者都不包含时，命令行和 web 接口都支持输入参数来手动指定入口类名。</p>
  </li>
  <li>
    <p>如果入口类实现了 <code>org.apache.flinkapi.common.Program</code>，则系统会调用它的 <code>getPlan(String...)</code> 来获得程序计划并执行。</p>
  </li>
  <li>
    <p>如果入口类没有实现 <code>org.apache.flinkapi.common.Program</code>，则系统调用入口类的 main 函数。</p>
  </li>
</ol>

<p><a href="#top" class="top pull-right"><span class="glyphicon glyphicon-chevron-up"></span> Back to top</a></p>

<h2 id="累加器和计数器">累加器和计数器</h2>
<p>累加器（Accumulators）由一个 <strong>add 操作</strong> 和一个 <strong>最终累加结果</strong> 组成，当任务结束后，才能获得累加结果。</p>

<p>最直接的累加器就是<strong>计数器</strong>（counter）。用户可以调用 <code>Accumulator.add(V value)</code> 来做累加。任务结束后， Flink 会合并所有的结果并将总结果返回给客户端。累加器在调试时很有作用，另外如果想快速知道数据的更多信息时也很有作用。</p>

<p>Flink 现在有如下的<strong>内置累加器</strong>， 他们都实现了 <a href="https://github.com/apache/flink/blob/master//flink-core/src/main/java/org/apache/flink/api/common/accumulators/Accumulator.java">Accumulator</a> 接口：</p>

<ul>
  <li><a href="https://github.com/apache/flink/blob/master//flink-core/src/main/java/org/apache/flink/api/common/accumulators/IntCounter.java"><strong>IntCounter</strong></a>,
<a href="https://github.com/apache/flink/blob/master//flink-core/src/main/java/org/apache/flink/api/common/accumulators/LongCounter.java"><strong>LongCounter</strong></a>
和 <a href="https://github.com/apache/flink/blob/master//flink-core/src/main/java/org/apache/flink/api/common/accumulators/DoubleCounter.java"><strong>DoubleCounter</strong></a>:
请看下方的例子了解如何使用计数器（counter）。</li>
  <li><a href="https://github.com/apache/flink/blob/master//flink-core/src/main/java/org/apache/flink/api/common/accumulators/Histogram.java"><strong>Histogram</strong></a>: Histogram 实现了离散数据的分布。内部实现上它只是一个从 Integer 到 Integer 的 map。你可以使用这个去计算值的分布，例如 word count 程序中每行单词数的分布。</li>
</ul>

<p><strong>如何使用累加器:</strong></p>

<p>首先你需要在自定义的转换函数中创建一个累加器（这里是一个计数器）。</p>

<figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="kd">private</span> <span class="n">IntCounter</span> <span class="n">numLines</span> <span class="o">=</span> <span class="k">new</span> <span class="nf">IntCounter</span><span class="o">();</span></code></pre></figure>

<p>然后，注册这个累加器对象，一般是在富函数（<em>rich</em> function）中的 <code>open()</code> 函数内， 如下，可以定义一个名字。</p>

<figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="n">getRuntimeContext</span><span class="o">().</span><span class="na">addAccumulator</span><span class="o">(</span><span class="s">&quot;num-lines&quot;</span><span class="o">,</span> <span class="k">this</span><span class="o">.</span><span class="na">numLines</span><span class="o">);</span></code></pre></figure>

<p>现在，你可以在这个 operator 函数的任何地方调用累加器了，包括<code>open()</code>和<code>close()</code>方法。</p>

<figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="k">this</span><span class="o">.</span><span class="na">numLines</span><span class="o">.</span><span class="na">add</span><span class="o">(</span><span class="mi">1</span><span class="o">);</span></code></pre></figure>

<p>最终结果会存储在由执行环境（execution environment）的 <code>execute()</code> 函数返回的 <code>JobExecutionResult</code> 对象中（当前这只在执行等待作业完成的情况下有效）。</p>

<figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="n">myJobExecutionResult</span><span class="o">.</span><span class="na">getAccumulatorResult</span><span class="o">(</span><span class="s">&quot;num-lines&quot;</span><span class="o">)</span></code></pre></figure>

<p>一个任务的所有的累加器共享一个命名空间。因此用户可以在不同的 operator 函数中使用相同的累加器。Flink 内部会合并所有的相同名字的累加器。</p>

<p>关于累加器和迭代器的一个注意点：当前累加器的结果只能在任务结束后才能获得。我们计划实现前一个迭代的结果可以在下一个迭代中获得。用户可以使用 <a href="https://github.com/apache/flink/blob/master//flink-java/src/main/java/org/apache/flink/api/java/operators/IterativeDataSet.java#L98">Aggregators</a> 去计算每个迭代的统计，然后基于统计结果来结束迭代。</p>

<p><strong>自定义累加器:</strong></p>

<p>用户可以通过实现 <code>Accumulator</code> 接口方便地创建自己的累加器。如果想要把自己实现的累加器加入到 Flink，请随意创建一个 pull request。</p>

<p>你可以选择是实现
<a href="https://github.com/apache/flink/blob/master//flink-core/src/main/java/org/apache/flink/api/common/accumulators/Accumulator.java">Accumulator</a>
还是 <a href="https://github.com/apache/flink/blob/master//flink-core/src/main/java/org/apache/flink/api/common/accumulators/SimpleAccumulator.java">SimpleAccumulator</a>。</p>

<p><code>Accumulator&lt;V,R&gt;</code> 非常灵活: 它定义了需要增加的值的类型 <code>V</code>, 和最终返回结果的类型 <code>R</code>。 例如，对于一个 histogram 来说，<code>V</code>  是一个数字，<code>R</code> 是一个 histogram。<code>SimpleAccumulator</code> 就是 V 和 R 是同一种类型，比如计数器。</p>

<p><a href="#top" class="top pull-right"><span class="glyphicon glyphicon-chevron-up"></span> Back to top</a></p>

<h2 id="并发执行">并发执行</h2>

<p>这个章节将介绍在 Flink 中如何设置并发执行。 一个 Flink 程序由多个 task (transformation/operator, data sources, sinks)组成。一个 task 会切分成几个实例中并发执行，每一个并发实例处理 task 输入数据的一个子集。task 的并发实例数称为 <em>parallelism</em>（并行度）。</p>

<p>一个 task 的并行度在 Flink 的不同级别中指定。</p>

<h3 id="operator-级别">Operator 级别</h3>

<p>独立的 operator，data source，data sink 可以通过调用 <code>setParallelism()</code> 来设置。例如：</p>

<div class="codetabs">
  <div data-lang="java">

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="kd">final</span> <span class="n">StreamExecutionEnvironment</span> <span class="n">env</span> <span class="o">=</span> <span class="n">StreamExecutionEnvironment</span><span class="o">.</span><span class="na">getExecutionEnvironment</span><span class="o">();</span>

<span class="n">DataStream</span><span class="o">&lt;</span><span class="n">String</span><span class="o">&gt;</span> <span class="n">text</span> <span class="o">=</span> <span class="o">[...]</span>
<span class="n">DataStream</span><span class="o">&lt;</span><span class="n">Tuple2</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">Integer</span><span class="o">&gt;&gt;</span> <span class="n">wordCounts</span> <span class="o">=</span> <span class="n">text</span>
    <span class="o">.</span><span class="na">flatMap</span><span class="o">(</span><span class="k">new</span> <span class="nf">LineSplitter</span><span class="o">())</span>
    <span class="o">.</span><span class="na">keyBy</span><span class="o">(</span><span class="mi">0</span><span class="o">)</span>
    <span class="o">.</span><span class="na">timeWindow</span><span class="o">(</span><span class="n">Time</span><span class="o">.</span><span class="na">seconds</span><span class="o">(</span><span class="mi">5</span><span class="o">))</span>
    <span class="o">.</span><span class="na">sum</span><span class="o">(</span><span class="mi">1</span><span class="o">).</span><span class="na">setParallelism</span><span class="o">(</span><span class="mi">5</span><span class="o">);</span>

<span class="n">wordCounts</span><span class="o">.</span><span class="na">print</span><span class="o">();</span>

<span class="n">env</span><span class="o">.</span><span class="na">execute</span><span class="o">(</span><span class="s">&quot;Word Count Example&quot;</span><span class="o">);</span></code></pre></figure>

  </div>
  <div data-lang="scala">

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">env</span> <span class="k">=</span> <span class="nc">StreamExecutionEnvironment</span><span class="o">.</span><span class="n">getExecutionEnvironment</span>

<span class="k">val</span> <span class="n">text</span> <span class="k">=</span> <span class="o">[</span><span class="kt">...</span><span class="o">]</span>
<span class="k">val</span> <span class="n">wordCounts</span> <span class="k">=</span> <span class="n">text</span>
    <span class="o">.</span><span class="n">flatMap</span><span class="o">{</span> <span class="k">_</span><span class="o">.</span><span class="n">split</span><span class="o">(</span><span class="s">&quot; &quot;</span><span class="o">)</span> <span class="n">map</span> <span class="o">{</span> <span class="o">(</span><span class="k">_</span><span class="o">,</span> <span class="mi">1</span><span class="o">)</span> <span class="o">}</span> <span class="o">}</span>
    <span class="o">.</span><span class="n">keyBy</span><span class="o">(</span><span class="mi">0</span><span class="o">)</span>
    <span class="o">.</span><span class="n">timeWindow</span><span class="o">(</span><span class="nc">Time</span><span class="o">.</span><span class="n">seconds</span><span class="o">(</span><span class="mi">5</span><span class="o">))</span>
    <span class="o">.</span><span class="n">sum</span><span class="o">(</span><span class="mi">1</span><span class="o">).</span><span class="n">setParallelism</span><span class="o">(</span><span class="mi">5</span><span class="o">)</span>
<span class="n">wordCounts</span><span class="o">.</span><span class="n">print</span><span class="o">()</span>

<span class="n">env</span><span class="o">.</span><span class="n">execute</span><span class="o">(</span><span class="s">&quot;Word Count Example&quot;</span><span class="o">)</span></code></pre></figure>

  </div>
</div>

<h3 id="执行环境级别">执行环境级别</h3>

<p>就像<a href="#anatomy-of-a-flink-program">这里</a>提到过的，Flink 程序是在一个执行环境的上下文中运行的。一个执行环境为所有 operator，data source，data sink 定义了一个默认的并行度。执行环境的并行度可以被 operator 的并行度覆盖。</p>

<p>一个执行环境的默认并行度可以通过调用 <code>setParallelism()</code> 方法指定。要以并行度为 <code>3</code> 来执行所有的 operators, data sources, data sinks，可以如下这样设置执行环境的默认并行度：</p>

<div class="codetabs">
  <div data-lang="java">

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="kd">final</span> <span class="n">StreamExecutionEnvironment</span> <span class="n">env</span> <span class="o">=</span> <span class="n">StreamExecutionEnvironment</span><span class="o">.</span><span class="na">getExecutionEnvironment</span><span class="o">();</span>
<span class="n">env</span><span class="o">.</span><span class="na">setParallelism</span><span class="o">(</span><span class="mi">3</span><span class="o">);</span>

<span class="n">DataStream</span><span class="o">&lt;</span><span class="n">String</span><span class="o">&gt;</span> <span class="n">text</span> <span class="o">=</span> <span class="o">[...]</span>
<span class="n">DataStream</span><span class="o">&lt;</span><span class="n">Tuple2</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">Integer</span><span class="o">&gt;&gt;</span> <span class="n">wordCounts</span> <span class="o">=</span> <span class="o">[...]</span>
<span class="n">wordCounts</span><span class="o">.</span><span class="na">print</span><span class="o">();</span>

<span class="n">env</span><span class="o">.</span><span class="na">execute</span><span class="o">(</span><span class="s">&quot;Word Count Example&quot;</span><span class="o">);</span></code></pre></figure>

  </div>
  <div data-lang="scala">

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">env</span> <span class="k">=</span> <span class="nc">StreamExecutionEnvironment</span><span class="o">.</span><span class="n">getExecutionEnvironment</span>
<span class="n">env</span><span class="o">.</span><span class="n">setParallelism</span><span class="o">(</span><span class="mi">3</span><span class="o">)</span>

<span class="k">val</span> <span class="n">text</span> <span class="k">=</span> <span class="o">[</span><span class="kt">...</span><span class="o">]</span>
<span class="k">val</span> <span class="n">wordCounts</span> <span class="k">=</span> <span class="n">text</span>
    <span class="o">.</span><span class="n">flatMap</span><span class="o">{</span> <span class="k">_</span><span class="o">.</span><span class="n">split</span><span class="o">(</span><span class="s">&quot; &quot;</span><span class="o">)</span> <span class="n">map</span> <span class="o">{</span> <span class="o">(</span><span class="k">_</span><span class="o">,</span> <span class="mi">1</span><span class="o">)</span> <span class="o">}</span> <span class="o">}</span>
    <span class="o">.</span><span class="n">keyBy</span><span class="o">(</span><span class="mi">0</span><span class="o">)</span>
    <span class="o">.</span><span class="n">timeWindow</span><span class="o">(</span><span class="nc">Time</span><span class="o">.</span><span class="n">seconds</span><span class="o">(</span><span class="mi">5</span><span class="o">))</span>
    <span class="o">.</span><span class="n">sum</span><span class="o">(</span><span class="mi">1</span><span class="o">)</span>
<span class="n">wordCounts</span><span class="o">.</span><span class="n">print</span><span class="o">()</span>

<span class="n">env</span><span class="o">.</span><span class="n">execute</span><span class="o">(</span><span class="s">&quot;Word Count Example&quot;</span><span class="o">)</span></code></pre></figure>

  </div>
</div>

<h3 id="客户端级别">客户端级别</h3>

<p>当提交任务到 Flink 时，客户端可以设置并行度。这个客户端可以是一个 Java 或 Scala 程序。 Flink 的命令行客户端(Command-line interface CLI)就是这样一个例子。</p>

<p>在 CLI 客户端中，可以通过 <code>-p</code> 参数来设置并行度，例如：</p>

<div class="highlight"><pre><code>./bin/flink run -p 10 ../examples/*WordCount-java*.jar
</code></pre></div>

<p>在 Java/Scala 程序中，并行度可以如下这样设置：</p>

<div class="codetabs">
  <div data-lang="java">

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="k">try</span> <span class="o">{</span>
    <span class="n">PackagedProgram</span> <span class="n">program</span> <span class="o">=</span> <span class="k">new</span> <span class="nf">PackagedProgram</span><span class="o">(</span><span class="n">file</span><span class="o">,</span> <span class="n">args</span><span class="o">);</span>
    <span class="n">InetSocketAddress</span> <span class="n">jobManagerAddress</span> <span class="o">=</span> <span class="n">RemoteExecutor</span><span class="o">.</span><span class="na">getInetFromHostport</span><span class="o">(</span><span class="s">&quot;localhost:6123&quot;</span><span class="o">);</span>
    <span class="n">Configuration</span> <span class="n">config</span> <span class="o">=</span> <span class="k">new</span> <span class="nf">Configuration</span><span class="o">();</span>

    <span class="n">Client</span> <span class="n">client</span> <span class="o">=</span> <span class="k">new</span> <span class="nf">Client</span><span class="o">(</span><span class="n">jobManagerAddress</span><span class="o">,</span> <span class="n">config</span><span class="o">,</span> <span class="n">program</span><span class="o">.</span><span class="na">getUserCodeClassLoader</span><span class="o">());</span>

    <span class="c1">// set the parallelism to 10 here</span>
    <span class="n">client</span><span class="o">.</span><span class="na">run</span><span class="o">(</span><span class="n">program</span><span class="o">,</span> <span class="mi">10</span><span class="o">,</span> <span class="kc">true</span><span class="o">);</span>

<span class="o">}</span> <span class="k">catch</span> <span class="o">(</span><span class="n">ProgramInvocationException</span> <span class="n">e</span><span class="o">)</span> <span class="o">{</span>
    <span class="n">e</span><span class="o">.</span><span class="na">printStackTrace</span><span class="o">();</span>
<span class="o">}</span></code></pre></figure>

  </div>
  <div data-lang="scala">

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">try</span> <span class="o">{</span>
    <span class="nc">PackagedProgram</span> <span class="n">program</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">PackagedProgram</span><span class="o">(</span><span class="n">file</span><span class="o">,</span> <span class="n">args</span><span class="o">)</span>
    <span class="nc">InetSocketAddress</span> <span class="n">jobManagerAddress</span> <span class="k">=</span> <span class="nc">RemoteExecutor</span><span class="o">.</span><span class="n">getInetFromHostport</span><span class="o">(</span><span class="s">&quot;localhost:6123&quot;</span><span class="o">)</span>
    <span class="nc">Configuration</span> <span class="n">config</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Configuration</span><span class="o">()</span>

    <span class="nc">Client</span> <span class="n">client</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Client</span><span class="o">(</span><span class="n">jobManagerAddress</span><span class="o">,</span> <span class="k">new</span> <span class="nc">Configuration</span><span class="o">(),</span> <span class="n">program</span><span class="o">.</span><span class="n">getUserCodeClassLoader</span><span class="o">())</span>

    <span class="c1">// set the parallelism to 10 here</span>
    <span class="n">client</span><span class="o">.</span><span class="n">run</span><span class="o">(</span><span class="n">program</span><span class="o">,</span> <span class="mi">10</span><span class="o">,</span> <span class="kc">true</span><span class="o">)</span>

<span class="o">}</span> <span class="k">catch</span> <span class="o">{</span>
    <span class="k">case</span> <span class="n">e</span><span class="k">:</span> <span class="kt">Exception</span> <span class="o">=&gt;</span> <span class="n">e</span><span class="o">.</span><span class="n">printStackTrace</span>
<span class="o">}</span></code></pre></figure>

  </div>
</div>

<h3 id="系统级别">系统级别</h3>

<p>可以在配置文件 <code>./conf/flink-conf.yaml</code> 中设置 <code>parallelism.default</code>，从而设置系统范围的默认并行度。查看 <a href="/1.1.0/setup/config.html">配置</a> 文档了解更多。</p>

<p><a href="#top" class="top pull-right"><span class="glyphicon glyphicon-chevron-up"></span> Back to top</a></p>

<h2 id="执行计划">执行计划</h2>

<p>根据各种参数，比如数据大小、集群机器数，Flink 的优化器会自动为你的程序选择一种执行策略。在很多情况下，对于了解 Flink 究竟是如何执行你的程序是很有帮助的。</p>

<p><strong>计划可视化工具</strong></p>

<p>Flink 自带了执行计划的可视化工具，可视化工具位于 <code>tools/planVisualizer.html</code>。它接受一个代表任务执行计划的 JSON 数据，并将它展示成一个带执行策略注释的图。</p>

<p>下面代码展示如何打印执行计划 JSON:</p>

<div class="codetabs">
  <div data-lang="java">

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="kd">final</span> <span class="n">ExecutionEnvironment</span> <span class="n">env</span> <span class="o">=</span> <span class="n">ExecutionEnvironment</span><span class="o">.</span><span class="na">getExecutionEnvironment</span><span class="o">();</span>

<span class="o">...</span>

<span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="n">env</span><span class="o">.</span><span class="na">getExecutionPlan</span><span class="o">());</span></code></pre></figure>

  </div>
  <div data-lang="scala">

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">env</span> <span class="k">=</span> <span class="nc">ExecutionEnvironment</span><span class="o">.</span><span class="n">getExecutionEnvironment</span>

<span class="o">...</span>

<span class="n">println</span><span class="o">(</span><span class="n">env</span><span class="o">.</span><span class="n">getExecutionPlan</span><span class="o">())</span></code></pre></figure>

  </div>
</div>

<p>要可视化执行计划，需要按以下步骤：</p>

<ol>
  <li><strong>打开</strong> 用浏览器打开 <code>planVisualizer.html</code>,</li>
  <li><strong>粘贴</strong> JSON 字符串到文本框中, 然后</li>
  <li><strong>点击</strong> draw 按钮。</li>
</ol>

<p>之后，一个详细的执行计划图就会被展示出来</p>

<p><img alt="A flink job execution graph." src="fig/plan_visualizer.png" width="80%" /></p>

<p><strong>Web 接口</strong></p>

<p>Flink提供 web 接口用来提交和执行任务。如果你选择使用 web 接口提交打包的程序，你可以选择看到计划图。</p>

<p>启动 web 接口的脚本位于 <code>bin/start-webclient.sh</code>。启动 webclient（8080端口）后，你可以上传程序，上传的程序会列在左边可使用的程序列表中。</p>

<p>你也可以在页面底部的文本框中指定程序的输入参数。选中了 plan visualization 选项框的话，在执行程序前，会展示执行计划图。</p>

<p><a href="#top" class="top pull-right"><span class="glyphicon glyphicon-chevron-up"></span> Back to top</a></p>

     <div class="footer">
      发现错误？想参与编辑？
      <a href="https://github.com/flink-china/flink-china-doc/edit/1.1.0/apis/common/index.md" target="_blank">
        在 Github 上编辑此页！
      </a>
    </div>
  </div>
  

  
</div>

    </div><!-- /.container -->

    <!-- jQuery (necessary for Bootstrap's JavaScript plugins) -->
    <script src="//cdn.bootcss.com/jquery/1.11.2/jquery.min.js"></script>
    <!-- Include all compiled plugins (below), or include individual files as needed -->
    <script src="//cdn.bootcss.com/bootstrap/3.3.4/js/bootstrap.min.js"></script>
    <script src="//cdn.bootcss.com/anchor-js/3.1.0/anchor.min.js"></script>
    <script src="/1.1.0/page/js/flink.js"></script>

    <!-- Google Analytics -->
    <!-- script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-52545728-1', 'auto');
      ga('send', 'pageview');
    </script -->

    <!-- Baidu Analytics -->
    <script>
      var _hmt = _hmt || [];
      (function() {
        var hm = document.createElement("script");
        hm.src = "//hm.baidu.com/hm.js?835985ad7943d8c24bc3c1f155b7d4a2";
        var s = document.getElementsByTagName("script")[0]; 
        s.parentNode.insertBefore(hm, s);
      })();
    </script>


    <!-- Disqus -->
    
  </body>
</html>
